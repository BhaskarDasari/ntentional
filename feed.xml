<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://www.ntentional.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.ntentional.com/" rel="alternate" type="text/html" /><updated>2020-06-29T15:07:19-05:00</updated><id>https://www.ntentional.com/feed.xml</id><title type="html">ntentional</title><subtitle>Morgan McGuire's machine learning journey through blogs and code</subtitle><entry><title type="html">Text Data Cleanup - Embedding Visualisation</title><link href="https://www.ntentional.com/2020/06/29/Text-Cleaning-With-Clustering.html" rel="alternate" type="text/html" title="Text Data Cleanup - Embedding Visualisation" /><published>2020-06-29T00:00:00-05:00</published><updated>2020-06-29T00:00:00-05:00</updated><id>https://www.ntentional.com/2020/06/29/Text-Cleaning-With-Clustering</id><content type="html" xml:base="https://www.ntentional.com/2020/06/29/Text-Cleaning-With-Clustering.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-29-Text-Cleaning-With-Clustering.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;In order for Machine Translation to be useful in the real world, we should should strive to train it on high quality translation data. This is doubly true for lower-resource languages such as Irish, where clean training data is relatively limited. In this article we will try and identify and remove clusters of dirty/noisey samples in our parallalel dataset. The stages we will go through are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Generate&lt;/strong&gt; embeddings from a pre-trained multi-lingual model, XLM-RoBERTa&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualise&lt;/strong&gt; these embeddings using a dimensionality technique via UMAP&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identify&lt;/strong&gt; clusters in a sample of the data that seem to be of low translation quality via Bokeh&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remove&lt;/strong&gt; similar samples from the main dataset via nmslib&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Dimension-Reduction---UMAP&quot;&gt;Dimension Reduction - UMAP&lt;a class=&quot;anchor-link&quot; href=&quot;#Dimension-Reduction---UMAP&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Dimensionality reduction techniques attempt to find the latent features in your data&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://umap-learn.readthedocs.io/en/latest/index.html&quot;&gt;Uniform Manifold Approximation and Projection (UMAP)&lt;/a&gt; is a dimension reduction technique published in &lt;a href=&quot;https://arxiv.org/abs/1802.03426&quot;&gt;2018 by McInnes and Healy&lt;/a&gt; that can be used for visualisation of high dimensional data, similarly to [[t-SNE]].&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Its main advantage is that it is fast (faster than t-SNE when dealing with large datasets) and also better maintains the global structure of the data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://pair-code.github.io/understanding-umap/#:~:text=In%20the%20simplest%20sense%2C%20UMAP,behind%20them%20is%20remarkably%20simple&quot;&gt;Pair Code has an excellent explanation complete with visualisations of UMAP&lt;/a&gt; if you'd like to learn more and docs also have excellent &lt;a href=&quot;https://umap-learn.readthedocs.io/en/latest/interactive_viz.html&quot;&gt;interactive visualisation examples from users&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It also has &lt;a href=&quot;https://umap-learn.readthedocs.io/en/latest/index.html&quot;&gt;beautifully well-written&lt;/a&gt; documentation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;McInnes gives a useful overview of UMAP here at the SciPy 2018 conference:

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/watch?v=nq6iPZVUxZU&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;

## Similarity Search - nmslib&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/nmslib/nmslib/blob/master/python_bindings/notebooks/search_sparse_cosine.ipynb&quot;&gt;nmslib&lt;/a&gt; is an &quot;&lt;strong&gt;efficient similarity search library and a toolkit for evaluation of k-NN methods for generic non-metric spaces&lt;/strong&gt;&quot; and is easily installed with &lt;code&gt;pip install nmslib&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In testing &lt;a href=&quot;http://www.benfrederickson.com/approximate-nearest-neighbours-for-recommender-systems/&quot;&gt;Ben Frederickson found&lt;/a&gt; that between nmslib, &lt;a href=&quot;https://engineering.fb.com/ml-applications/faiss-a-library-for-efficient-similarity-search/&quot;&gt;FAISS&lt;/a&gt; (Facebook) and &lt;a href=&quot;https://github.com/spotify/annoy&quot;&gt;annoy&lt;/a&gt; (Spotify) nmslib was the fastest nearest neighbours library for CPU. Note FAISS on GPU is blazes past nmslib and annoy, but can also difficult to set up.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/milvus-io/milvus&quot;&gt;Milvus&lt;/a&gt; is an interesting library that was open sourced in late 2019 which offers similarity search using FAISS, nmslib or annoy as well as GPU capability. If I had had more time I would have explored this further&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ElasticSearch &lt;a href=&quot;https://www.elastic.co/blog/text-similarity-search-with-vectors-in-elasticsearch&quot;&gt;post&lt;/a&gt; and &lt;a href=&quot;https://medium.com/analytics-vidhya/elasticbert-information-retrieval-using-bert-and-elasticsearch-51fef465b9ae&quot;&gt;article&lt;/a&gt; is yet another tool we could use to carry out the similarity search between our text embeddings.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finally,  &lt;a href=&quot;www.dair.ai&quot;&gt;DAIR.ai&lt;/a&gt; recently posted a video called &lt;a href=&quot;https://www.youtube.com/watch?v=VHm6_uC4vxM&quot;&gt;&quot;101 Ways to Solve Search&quot;&lt;/a&gt; by &lt;a href=&quot;www.pratik.ai&quot;&gt;Pratik Bhavsar&lt;/a&gt; which is a great introduction to how search works in general. Also &lt;a href=&quot;models.pratik.ai&quot;&gt;models.pratik.ai&lt;/a&gt; is a really great flow chart visualisation which he tries to keep up to date of the models and techniques available for semantic search and NLP in general

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/watch?v=VHm6_uC4vxM&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;BONUS: &lt;a href=&quot;https://www.kaggle.com/hmendonca/proper-clustering-with-facenet-embeddings-eda&quot;&gt;@hmendonca's EDA notebook on kaggle&lt;/a&gt; is an excellent example showing how to use annoy to group and display similar images (faces in this case).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Text-Embeddings---XLM-R&quot;&gt;Text Embeddings - XLM-R&lt;a class=&quot;anchor-link&quot; href=&quot;#Text-Embeddings---XLM-R&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We derive our text embedding by passing the text sample though &lt;a href=&quot;https://arxiv.org/abs/1911.02116&quot;&gt;XLM-RoBERTa Large&lt;/a&gt; and extracting the values in final hidden layer. XLM-R  is a multilingual model and should work reasonably well for both Irish and English&lt;/p&gt;
&lt;p&gt;Research has been done on BERT to show that by concatenating the final 4 layers of the model one gets even richer contextual embeddings. In the interest of simplicity we will stick to the final layer only for the moment, although using additional layers would be an interesting area of exploration!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Text-Embeddings-for-Fun-and-Profit&quot;&gt;Text Embeddings for Fun and Profit&lt;a class=&quot;anchor-link&quot; href=&quot;#Text-Embeddings-for-Fun-and-Profit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Text embeddings are incredibly valuable and can also be used for things like spell checking; have a look at &lt;a href=&quot;https://blog.usejournal.com/a-simple-spell-checker-built-from-word-vectors-9f28452b6f26&quot;&gt;@er214's post&lt;/a&gt; and &lt;a href=&quot;https://github.com/er214/spellchecker&quot;&gt;notebook&lt;/a&gt; to see how they &lt;strong&gt;used GloVe word embeddings to create a spell-checker&lt;/strong&gt; for their dataset. The &lt;a href=&quot;https://forums.fast.ai/t/nlp-any-libraries-dictionaries-out-there-for-fixing-common-spelling-errors/16411&quot;&gt;fastai forums post&lt;/a&gt; is also worth a read if you have time, they also created a &quot;pretentiousness&quot; embedding to score news outlets 🤣. While we are using embeddings for chunks of text, as opposed to individual words, the concept is the same.&lt;/p&gt;
&lt;h2 id=&quot;Generate-our-Embeddings&quot;&gt;Generate our Embeddings&lt;a class=&quot;anchor-link&quot; href=&quot;#Generate-our-Embeddings&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h4 id=&quot;Load-Raw-ParaCrawl-Data&quot;&gt;Load Raw ParaCrawl Data&lt;a class=&quot;anchor-link&quot; href=&quot;#Load-Raw-ParaCrawl-Data&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;First lets load our raw data. This is data that has been crawled from the internet and contains a few different types of artifacts including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Non-latin scripts &lt;/li&gt;
&lt;li&gt;Other random characters (e.g. '©','³','º')&lt;/li&gt;
&lt;li&gt;Text samples that are unlikely to have been translated to Irish by a human, including&lt;ul&gt;
&lt;li&gt;Porn sites&lt;/li&gt;
&lt;li&gt;Lighting sites (who knows why?)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lets see how much we can find by turning our samples into embeddings and using dimenstionality reduction to visualise them.&lt;/p&gt;
&lt;p&gt;For fun, we'll label texts that contain &quot;sex&quot;, &quot;lighting&quot; and cyrillic characters like &quot;и&quot;, &quot;з&quot; or &quot;л&quot; see if they get clustered together when we visualise our word embeddings later. We will also lowercae our entire dataset; many of the legal texts here are fully written in uppercase, however right now we care more about the content of the text as opposed to the style&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Dataset has : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt; rows&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;[en] : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;en&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;[ga] : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ga&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;Dataset has : 784606 rows

[en] : green dog walkers is a regional programme involving most of the councils&amp;#39; in the leinster area.

[ga] : is clár réigiúnach é siúlóirí glasa madraí a bhaineann le formhór na gcomhairlí i gcúige laighin.
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Get-Pre-Trained-XLM-RoBERTa-Model&quot;&gt;Get Pre-Trained XLM-RoBERTa Model&lt;a class=&quot;anchor-link&quot; href=&quot;#Get-Pre-Trained-XLM-RoBERTa-Model&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Next we will initialise our XLM-RoBERTa model (commonly known as &quot;XLM-R&quot;). I chose this model as it is a multilingual model trained on 100 languages, including both English and Irish, if we choose to look at the Irish embeddings too.&lt;/p&gt;
&lt;p&gt;Here we will embed the &lt;strong&gt;English&lt;/strong&gt; samples as this is where a lot of the noise in the dataset seems to stem from.
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;We use XLM-R Large in this example, but XLM-R Base will also work well
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Set-up-Tokenizer-and-Padding&quot;&gt;Set up Tokenizer and Padding&lt;a class=&quot;anchor-link&quot; href=&quot;#Set-up-Tokenizer-and-Padding&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;As part of setting up our dataloader we'll need to define our:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tokenizer Transform, which is a wrapper around the HuggingFace tokenizer &lt;/li&gt;
&lt;li&gt;Function to add padding to each sample so that we can batch our samples&lt;/li&gt;
&lt;li&gt;Function to create a padding mask so that our model doesn't attend over the padding tokens&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Create-our-Dataloader&quot;&gt;Create our Dataloader&lt;a class=&quot;anchor-link&quot; href=&quot;#Create-our-Dataloader&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Now we are ready to create our dataloader so that we can quickly iterate through our samples. I'm using fastai here, however you could also use either a PyTorch or Tensorflow dataloader here, the rest of this notebook doesn't have a fastai dependency.&lt;/p&gt;
&lt;p&gt;To start, we'll look at a random sample of 40,000 samples, about 5% of our data. Remember we are only retrieving embeddings for our English samples for now.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;You can see the English sample below, including the special tokens &lt;code&gt;&amp;lt; s &amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt; /s &amp;gt;&lt;/code&gt; used by XLM-R to denote the start and end of the sequence. You can also see all the padding needed for this sample.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samp_dls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samp_texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;&amp;lt;s&amp;gt; (i) in subsection (1) by deleting the definition of “dependant”, and&amp;lt;/s&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;&amp;lt;pad&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Grab-the-Embeddings&quot;&gt;Grab the Embeddings&lt;a class=&quot;anchor-link&quot; href=&quot;#Grab-the-Embeddings&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now we're ready to retrieve our embeddings from the pretrained multi-lingual model. We do this by simply passing our samples to the model and saving the output activations from the last layer of the model. From this we can generate an embedding of size (40000, 1024) which we can then pass to our dimensionality reduction algorithm.&lt;/p&gt;
&lt;p&gt;Processing 40k samples with UMAP takes about 5 minutes. After a little testing with &lt;code&gt;n_neighbors&lt;/code&gt; and &lt;code&gt;min_dist&lt;/code&gt; I found the defaults work quite well although its always worth playing around with the parameters and distance metric used.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;strong&gt;Scaling your Embeddings&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One thing to consider might be whether you should scale your embeddings. The embeddings used here had mean 0 and standard deviation of 0.5, normalising them to (0,1) didn't seem to have much of an impact on the UMAP visualisation so it is not done here. Scikit-Learn has a &lt;a href=&quot;https://scikit-learn.org/stable/modules/preprocessing.html&quot;&gt;wide variety of scaling functions&lt;/a&gt; if you do need to scale your data.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Remove-similar-samples-from-the-entire-dataset&quot;&gt;Remove similar samples from the entire dataset&lt;a class=&quot;anchor-link&quot; href=&quot;#Remove-similar-samples-from-the-entire-dataset&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We will remove items by:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Visually &lt;strong&gt;identifying&lt;/strong&gt; similar noisey embeddings&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Taking the &lt;strong&gt;average of these embeddings&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Calculating a &lt;strong&gt;distance&lt;/strong&gt; between this average embedding and all of the embeddings in our entire dataset&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Removing embeddings that are within a certain distance to the average embeddings&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Visualise:-Dimensionality-Reduction-with-UMAP&quot;&gt;Visualise: Dimensionality Reduction with UMAP&lt;a class=&quot;anchor-link&quot; href=&quot;#Visualise:-Dimensionality-Reduction-with-UMAP&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;First we use umap to reduce the embedding space to 2 dimensions, then we plot the embedding using Bokeh, which enables us to dynamically select different regions of interest, enabling us to interactively explore our dataset&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samp_mapper&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;umap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UMAP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samp_embs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;![](&lt;/span&gt;my_icons/20200612_nlp-irish/nlp-irish-grab.png&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;/bin/sh: -c: line 0: syntax error near unexpected token `my_icons/20200612_nlp-irish/nlp-irish-grab.png&amp;#39;
/bin/sh: -c: line 0: `[](my_icons/20200612_nlp-irish/nlp-irish-grab.png)&amp;#39;
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Identify-clusters-in-a-sample-of-the-data-that-seem-to-be-of-low-translation-quality&quot;&gt;Identify clusters in a sample of the data that seem to be of low translation quality&lt;a class=&quot;anchor-link&quot; href=&quot;#Identify-clusters-in-a-sample-of-the-data-that-seem-to-be-of-low-translation-quality&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Can we identify suspect looking clusters of data? Yes!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;We can see the orange &quot;islands&quot; that we have labelled all contain text related to &quot;lighting&quot;, &quot;LED&quot;, &quot;Lamps&quot; etc, some of which are not even in English.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The sparse cluster of green blue points and their neighbours are also full of language related to pornography&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We don't see so many Cryllic points, however this was also the least common of our labels, comprising only (0.07% of our labels)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other &quot;islands&quot; that can identified by hovering over them include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Arabic texts&lt;/li&gt;
&lt;li&gt;Website footers&lt;/li&gt;
&lt;li&gt;Text from jewellery sites (e.g. Pandora) and also clothing sites&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below you can see some of the Arabic texts in our main dataset we have discovered:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ga&lt;/th&gt;
      &lt;th&gt;en&lt;/th&gt;
      &lt;th&gt;noise_type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;572564&lt;/th&gt;
      &lt;td&gt;مــحل الإقـامة: الـ riyadh&lt;/td&gt;
      &lt;td&gt;مــحل الإقـامة: ..ايـ جنوب ــران..&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;570189&lt;/th&gt;
      &lt;td&gt;رد: درس..استخدآم content-aware scale..~&lt;/td&gt;
      &lt;td&gt;مــحل الإقـامة: طيبهـ الطيبهـ&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;567067&lt;/th&gt;
      &lt;td&gt;ملعقة طعام خل ابيض&lt;/td&gt;
      &lt;td&gt;قلعة فن البكسل ( pixels art )&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;573439&lt;/th&gt;
      &lt;td&gt;هـــذاك لـــو انـــي مـــن الـوقــت مـهــزوم&lt;/td&gt;
      &lt;td&gt;قلعة دروس الايميج ريدي&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;571181&lt;/th&gt;
      &lt;td&gt;إرسال رسالة خاصة إلى adigatalostan&lt;/td&gt;
      &lt;td&gt;إرسال رسالة خاصة إلى nimrow&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I am fairly confident that none of the text in some these islands contain valuable translations and are likely the result of automated translations of suspect quality that we would like to remove.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Remove-similar-samples-from-the-full-dataset&quot;&gt;Remove similar samples from the full dataset&lt;a class=&quot;anchor-link&quot; href=&quot;#Remove-similar-samples-from-the-full-dataset&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;To remove similar samples we will calculate a distance metric between each of our selected embeddings and each of the embeddings in the full dataset. Alternativly we could also calculate the &quot;average embedding&quot; of all of our selected datapoints, and then calculate the distance between this average and each of the embeddings in the main dataset.&lt;/p&gt;
&lt;p&gt;From experimentation I found that the first option is more effective at identifying more of the noisy data we are looking for. In addtion, because our nms algorithm is super fast at retrieval there isn't any significant overhead to this approach over using the average embedding.&lt;/p&gt;
&lt;p&gt;First of all, we'll need to generate embeddings for all of our 780k text samples. This might take a little while depending on the size of your dataset so kick off the extraction and grab a coffee.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Sci-kit-Learn's-cosine_similarity&quot;&gt;Sci-kit Learn's cosine_similarity&lt;a class=&quot;anchor-link&quot; href=&quot;#Sci-kit-Learn's-cosine_similarity&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;By calculating the average embedding of our selected datapoints we can calculate the cosine similarity between it and all of the other embeddings in our full dataset, providing decent results!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;2724 rows with a similarity score greater than : 0.9995
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ga&lt;/th&gt;
      &lt;th&gt;en&lt;/th&gt;
      &lt;th&gt;noise_type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;570624&lt;/th&gt;
      &lt;td&gt;البحث عن المشاركات التي كتبها ɢнσғяαи&lt;/td&gt;
      &lt;td&gt;قلعة برامج الفيكتور illustrator و coreldraw&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;571940&lt;/th&gt;
      &lt;td&gt;safari مشاهدة ملفه الشخصي&lt;/td&gt;
      &lt;td&gt;مشكور على الاسرار ياعم&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;567896&lt;/th&gt;
      &lt;td&gt;رسالة إدارية رسالة إدارية&lt;/td&gt;
      &lt;td&gt;دورة الفوتوشوب cs5 للمبتدئين&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;573774&lt;/th&gt;
      &lt;td&gt;الله يعافيك أخي الفاضل&lt;/td&gt;
      &lt;td&gt;ممكن تعلميني ctrl+f اختصار لـ إيش بالظبط&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;568595&lt;/th&gt;
      &lt;td&gt;إرسال رسالة خاصة إلى fahooody&lt;/td&gt;
      &lt;td&gt;إرسال رسالة خاصة إلى رجل أعمال&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;strong&gt;We could stop at this point and continue to loop through selecting new datapoints of interest and removing them from our full dataset, but for fun lets look at another way to do similarity search, using nmslib&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Creating-a-nmslib-Index&quot;&gt;Creating a nmslib Index&lt;a class=&quot;anchor-link&quot; href=&quot;#Creating-a-nmslib-Index&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;&lt;em&gt;As an alternative to Sci-kit Learn&amp;#8217;s cosine similarity function we can also use nmslib to calculate our similarity. Note this method is slower given our needs in this example, but its always fun to work with a new technology&lt;/em&gt; 😀
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Once we have all of our embeddings we can create our index with nmslib. This is the most time-consuming part of this process, it took 47minutes for the index to be created in this example, although there are other nmslib settings thatn can reduce this to ~15minutes.&lt;/p&gt;
&lt;p&gt;We create an index for our entire dataset &lt;strong&gt;only once&lt;/strong&gt;.  We create an index for the entire dataset because we will likely have multiple queries we do not want to re-create a new index each time as it will really slow down how fast we can identify and remove low quality data.
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;(This index will now include our sample datapoints, which are the same datapoints that we use in our query to the index. Therefore we will have to exclude these sample datapoints from our query result)
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Querying-the-Index&quot;&gt;Querying the Index&lt;a class=&quot;anchor-link&quot; href=&quot;#Querying-the-Index&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Below are the sampled results from querying the full dataset, found through similarity search with an average embedding of the selection from the bokeh plot:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;strong&gt;Arabic&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;1691 ids returned from query
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ga&lt;/th&gt;
      &lt;th&gt;en&lt;/th&gt;
      &lt;th&gt;noise_type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;566807&lt;/th&gt;
      &lt;td&gt;قلعة فن البكسل ( pixels art )&lt;/td&gt;
      &lt;td&gt;طريقه عمل اطار منقط&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;571586&lt;/th&gt;
      &lt;td&gt;مواقع الارسال المجانى free sms ( 1 2)&lt;/td&gt;
      &lt;td&gt;لا تستطيع الرد على المواضيع&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;571682&lt;/th&gt;
      &lt;td&gt;قلعة دروس الفيكتور illustrator و coreldraw&lt;/td&gt;
      &lt;td&gt;اللهم صلي وسلم على نبينا محمد&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;570557&lt;/th&gt;
      &lt;td&gt;مــحل الإقـامة: jordan - palestine&lt;/td&gt;
      &lt;td&gt;قلعة الصور الخاصة بالتصميم&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;566810&lt;/th&gt;
      &lt;td&gt;مــحل الإقـامة: jordan - palestine&lt;/td&gt;
      &lt;td&gt;مــحل الإقـامة: في الفوتوشوب&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;strong&gt;Lighting&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;1699 ids returned from query
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ga&lt;/th&gt;
      &lt;th&gt;en&lt;/th&gt;
      &lt;th&gt;noise_type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;690718&lt;/th&gt;
      &lt;td&gt;an tsín bhí guangdong soilse linn snámha faoi stiúir monaróirí agus atá liostaithe anseo a fháil ag an soilsiú karnar.&lt;/td&gt;
      &lt;td&gt;the featured china guangdong 3x5 watts led-e27 manufacturers and listed here are sourced by the karnar lighting.&lt;/td&gt;
      &lt;td&gt;lighting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;477330&lt;/th&gt;
      &lt;td&gt;foinse do gairdín lawn monaróirí ag soilsiú karnar zhongshan &amp;amp; leictreon mhonarcha.&lt;/td&gt;
      &lt;td&gt;source for high power led wall washer 144w led wall washer manufacturers at zhongshan karnar lighting &amp;amp; electron factory.&lt;/td&gt;
      &lt;td&gt;lighting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;479274&lt;/th&gt;
      &lt;td&gt;an tsín bhí guangdong cumhacht ard-éadrom lawn faoi stiúir monaróirí agus atá liostaithe anseo a fháil ag an soilsiú karnar.&lt;/td&gt;
      &lt;td&gt;the featured china guangdong 3 watts led under ground lights round type manufacturers and listed here are sourced by the karnar lighting.&lt;/td&gt;
      &lt;td&gt;lighting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;636797&lt;/th&gt;
      &lt;td&gt;an tsín bhí guangdong faoi stiúir tube monaróirí agus atá liostaithe anseo a fháil ag an soilsiú karnar.&lt;/td&gt;
      &lt;td&gt;the featured china guangdong led spot light flash lamp and fancy ball manufacturers and listed here are sourced by the karnar lighting.&lt;/td&gt;
      &lt;td&gt;lighting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;692603&lt;/th&gt;
      &lt;td&gt;an tsín bhí guangdong faoi stiúir connectable soilse na nollag monaróirí agus atá liostaithe anseo a fháil ag an soilsiú karnar.&lt;/td&gt;
      &lt;td&gt;the featured china guangdong high-power led colorful 500w led wall washer manufacturers and listed here are sourced by the karnar lighting.&lt;/td&gt;
      &lt;td&gt;lighting&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;strong&gt;Website Footer&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;1825 ids returned from query
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ga&lt;/th&gt;
      &lt;th&gt;en&lt;/th&gt;
      &lt;th&gt;noise_type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;696159&lt;/th&gt;
      &lt;td&gt;©2005-2010 karnardéan teagmháil linnnasc linnléarscáil an láithreáinlast modified: august 08 2016 02:43:19.&lt;/td&gt;
      &lt;td&gt;©2005-2010 karnarsambandlink okkurveftrélast modified: august 08 2016 04:06:45.&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;478396&lt;/th&gt;
      &lt;td&gt;©2005-2010 karnardéan teagmháil linnnasc linnléarscáil an láithreáinlast modified: july 31 2016 00:39:06.&lt;/td&gt;
      &lt;td&gt;©2005-2010 karnarcontact uslink ussite maplast modified: july 30 2016 22:04:01.&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;538977&lt;/th&gt;
      &lt;td&gt;©2005-2010 karnardéan teagmháil linnnasc linnléarscáil an láithreáinlast modified: july 14 2016 20:20:33.&lt;/td&gt;
      &lt;td&gt;©2005-2010 karnarcontact uslink ussite maplast modified: july 15 2016 01:50:20.&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;684675&lt;/th&gt;
      &lt;td&gt;©2005-2010 karnardéan teagmháil linnnasc linnléarscáil an láithreáinlast modified: august 08 2016 01:19:15.&lt;/td&gt;
      &lt;td&gt;©2005-2010 karnarcontactez-nousnous lierplan du sitelast modified: august 08 2016 03:54:30.&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;534904&lt;/th&gt;
      &lt;td&gt;©2005-2010 karnardéan teagmháil linnnasc linnléarscáil an láithreáinlast modified: july 31 2016 11:57:09.&lt;/td&gt;
      &lt;td&gt;©2005-2010 karnarcontact uslink ussite maplast modified: july 31 2016 09:46:30.&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;strong&gt;Clothing and Jewelery&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;1938 ids returned from query
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;ga&lt;/th&gt;
      &lt;th&gt;en&lt;/th&gt;
      &lt;th&gt;noise_type&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;641483&lt;/th&gt;
      &lt;td&gt;home:: uaireadóirí hublot:: sraith fusion classic:: sraith 45mm fusion classic:: macasamhail hublot classic comhleá sraith faire 45mm 511.zx.1170&lt;/td&gt;
      &lt;td&gt;home:: hublot watches:: classic fusion series:: classic fusion 45mm series:: replica hublot classic fusion 45mm watch series 401.mx.0123.gr [da02]&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;79453&lt;/th&gt;
      &lt;td&gt;pandora bead óir ivy óir - €10.23 : jewelry pandora saor, pandoraaustraliabracelets.com&lt;/td&gt;
      &lt;td&gt;pandora gold bead ivy gold - $11.00 : cheap pandora jewelry, pandoraaustraliabracelets.com&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;615744&lt;/th&gt;
      &lt;td&gt;clrip036a 925 sterling silver bán crystal ring - €28.83 : jewelry pandora saor , pandoraforyou.com&lt;/td&gt;
      &lt;td&gt;clrip036a 925 sterling silver white crystal ring - $31.00 : cheap pandora jewelry, pandoraforyou.com&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;67287&lt;/th&gt;
      &lt;td&gt;ard-chumhacht táirgí faoi stiúir &amp;gt; cumhacht ard-threoraithe colorful &amp;gt; product-list&lt;/td&gt;
      &lt;td&gt;led lighting &amp;gt; high-power led colorful &amp;gt; product-list lww-10 lww-10-108p lww-10-206p lww-8c-108p&lt;/td&gt;
      &lt;td&gt;lighting&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;635957&lt;/th&gt;
      &lt;td&gt;prada málaí láimhe p - br4692 caife leathar : seaicéad spyder, pradahandbags.top&lt;/td&gt;
      &lt;td&gt;prada borse p - br4692 coffee leather : spyder giacca , pradahandbags.top&lt;/td&gt;
      &lt;td&gt;na&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Removal&quot;&gt;Removal&lt;a class=&quot;anchor-link&quot; href=&quot;#Removal&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;If we like we can limit our removal to only very similar embeddings in the full dataset by only selecting the datapoints in the full dataset that are sufficiently close (lower score) to the average embedding, plotting the score distribution can help us decide on a suitable threshold&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Summary&quot;&gt;Summary&lt;a class=&quot;anchor-link&quot; href=&quot;#Summary&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Hopefully this gives you a sense of how you can explore and clean up large, noisy text datasets. You can open this notebook on github and test it for your own text dataset.&lt;/p&gt;
&lt;p&gt;As always, I would love to hear your feedback, what could have been written better or clearer, you can find me on twitter: &lt;a href=&quot;www.twitter.com/mcgenergy&quot;&gt;@mcgenergy&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Introducing nlp.irish!</title><link href="https://www.ntentional.com/irish/translation/nmt/mt/nlp/2020/06/12/introducing-nlp-irish.html" rel="alternate" type="text/html" title="Introducing nlp.irish!" /><published>2020-06-12T00:00:00-05:00</published><updated>2020-06-12T00:00:00-05:00</updated><id>https://www.ntentional.com/irish/translation/nmt/mt/nlp/2020/06/12/introducing-nlp-irish</id><content type="html" xml:base="https://www.ntentional.com/irish/translation/nmt/mt/nlp/2020/06/12/introducing-nlp-irish.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-06-12-introducing-nlp-irish.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;tl;dr&quot;&gt;tl;dr&lt;a class=&quot;anchor-link&quot; href=&quot;#tl;dr&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Looking through papers to track down the Irish-English parallel corpora they used was a real pain, so I built &lt;a href=&quot;nlp.irish&quot;&gt;&lt;strong&gt;nlp.irish&lt;/strong&gt;&lt;/a&gt; to document where to find them and how to process them easily&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;What?&quot;&gt;What?&lt;a class=&quot;anchor-link&quot; href=&quot;#What?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The intention behind &lt;a href=&quot;http://www.nlp.irish/&quot;&gt;nlp.irish&lt;/a&gt; is to make NLP for folks new to working with Irish a &lt;strong&gt;little easier&lt;/strong&gt; by documenting the datasets that are available out there, where to find them and how to load them to a pandas dataframe. &lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;The site is hosted on &lt;a href=&quot;https://github.com/nlp-irish/nlp.irish&quot;&gt;github here&lt;/a&gt; with the intention that it will grow via a &lt;strong&gt;collaborative effort&lt;/strong&gt; of those working in Irish NLP.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Where?&quot;&gt;Where?&lt;a class=&quot;anchor-link&quot; href=&quot;#Where?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;🇮🇪 &lt;a href=&quot;http://www.nlp.irish/&quot;&gt;&lt;strong&gt;nlp.irish&lt;/strong&gt;&lt;/a&gt; 🇮🇪&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Why?&quot;&gt;Why?&lt;a class=&quot;anchor-link&quot; href=&quot;#Why?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Irish is a low-resource language and every piece of data out there is valuable. &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Current-Data&quot;&gt;Current Data&lt;a class=&quot;anchor-link&quot; href=&quot;#Current-Data&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;As of writing, 5 commonly used Irish-English parallel corpora have been documented, with instructions on where to find them and &lt;strong&gt;code on how to process them&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ParaCrawl, v6&lt;/li&gt;
&lt;li&gt;DGT-TM, DGT-Translation Memory&lt;/li&gt;
&lt;li&gt;DCEP, Digital Corpus of the European Parliament&lt;/li&gt;
&lt;li&gt;ELRC, European Language Resource Coordination&lt;/li&gt;
&lt;li&gt;Tatoeba&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Contributing&quot;&gt;Contributing&lt;a class=&quot;anchor-link&quot; href=&quot;#Contributing&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Contributing is as easy as submitting a pull request on Github. Alternatively you can find me on twitter at &lt;a href=&quot;www.twitter.com/mcgenergy&quot;&gt;@mcgenergy&lt;/a&gt; and I can help update the site with your contibution.&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200612_nlp-irish/nlp-irish-grab.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Morgan McGuire</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.ntentional.com/images/nlpirish_logo.png" /><media:content medium="image" url="https://www.ntentional.com/images/nlpirish_logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">ICLR 2020: Efficient Deep Learning and More</title><link href="https://www.ntentional.com/papers/nlp/efficient-nlp/transformers/2020/05/09/iclr-highlights-2.html" rel="alternate" type="text/html" title="ICLR 2020: Efficient Deep Learning and More" /><published>2020-05-09T00:00:00-05:00</published><updated>2020-05-09T00:00:00-05:00</updated><id>https://www.ntentional.com/papers/nlp/efficient-nlp/transformers/2020/05/09/iclr-highlights-2</id><content type="html" xml:base="https://www.ntentional.com/papers/nlp/efficient-nlp/transformers/2020/05/09/iclr-highlights-2.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-09-iclr-highlights-2.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I was lucky enough to volunteer and attend (virtual) ICLR 2020. It delivered a huge amount of learning for me and I was fortunate to join some really great discussions.&lt;/p&gt;
&lt;p&gt;Efficient Deep Learning was big focus of many of the papers and in this second ICLR2020 article* I will focus on techniques presented that either enable more efficient training and/or inference from the papers I managed to see. There are also a couple of bonus papers I really liked at the end of this article.&lt;/p&gt;
&lt;p&gt;*&lt;a href=&quot;https://www.ntentional.com/papers/nlp/efficient-nlp/transformers/2020/05/05/iclr-hghlights.html&quot;&gt;In my first ICLR2020 article&lt;/a&gt; I highlight some of the new, more efficient transformer achitectures presented such as ELECTRA, Reformer and more.&lt;/p&gt;
&lt;h3 id=&quot;Note:-ICLR-Videos-Now-Online!&quot;&gt;Note: ICLR Videos Now &lt;a href=&quot;http://iclr.cc/virtual_2020/&quot;&gt;Online&lt;/a&gt;!&lt;a class=&quot;anchor-link&quot; href=&quot;#Note:-ICLR-Videos-Now-Online!&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;All of the ICLR paper talks and slides are now online, I &lt;strong&gt;highly recommend&lt;/strong&gt; watching the 5 to 15minutes videos accompanying each of the papers below for some excellent summaries and additional understanding&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Efficient-Deep-Learning&quot;&gt;Efficient Deep Learning&lt;a class=&quot;anchor-link&quot; href=&quot;#Efficient-Deep-Learning&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Training methods and architecture changes that can make Deep Learning models smaller/more efficient&lt;/p&gt;
&lt;h2 id=&quot;&amp;#9889;-Reducing-Transformer-Depth-on-Demand-with-Structured-Dropout-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual_2020/poster_SylO2yStDr.html&quot;&gt;Reducing Transformer Depth on Demand with Structured Dropout&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-Reducing-Transformer-Depth-on-Demand-with-Structured-Dropout-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The introduction of &lt;strong&gt;LayerDrop&lt;/strong&gt; in this paper was super exciting to read as it makes a (transformer) model much more robust to pruning while only having to train it once, unlike finding lottery tickets for example&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Essentially the idea is simple, just randomly remove/skip different layers during the forward pass in training like so:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/layerdrop.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LayerDrop can be implemented like so (see the link below for the author's full codebase)
&lt;pre&gt;&lt;code&gt;layer_drop = 0.2    # The authors dropped the layers with a 20% probability in all of their experiments
for layer in transformer.layers:
  if random(0,1) &amp;gt; layer_drop and self.training:
      x = layer(x)&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;This training setup confers 3 benefits:&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Increased Training Speed (training less layers)&lt;/strong&gt; &lt;ul&gt;
&lt;li&gt;in training the percentage increase in words per second increased almost linearly with the percentage of layers dropped&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strong regulariser&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;NLP models trained with layerDrop seem to perform better than baseline models trained without it (e.g. EN-DE Transformer performance improvement)&lt;/li&gt;
&lt;li&gt;Increased robustness of deeper models which enables you to increase the number of layers in your model. The authors doubled the encoder depth in their WMT14 EN-DE transformer translation model for a new SOTA BLEU score.&lt;/li&gt;
&lt;li&gt;Increases model stability&lt;/li&gt;
&lt;li&gt;Note the authors also reduced DropOut slightly when training to compensate for the additional regularisation of LayerDrop&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduction in model size&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;A model trained with LayerDrop can be pruned to any desired depth for inference and still maintain robust performance &lt;strong&gt;without additional fine-tuning&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;The specific type of pruning used for inference also did not seem to matter although &lt;strong&gt;dropping every other layer&lt;/strong&gt; seemd to offer strong performance while being straightforward to implement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Unfortunatley when I asked during the Q&amp;amp;A whether this could be applied to when fine-tuning existing pre-trained transformer models, such as those in HuggingFace's library, one of the authors replied that they had tried it but it didn't have great results. Their theory was that these transformers had learned so much during pre-training that a little bit of fine-tuning using LayerDrop wasn't able to have enough of an influence on the model weights to confer this robustness.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Code for LayerDrop and &lt;strong&gt;models pre-trained with LayerDrop&lt;/strong&gt; can be &lt;a href=&quot;https://github.com/pytorch/fairseq/tree/master/examples/layerdrop&quot;&gt;found here&lt;/a&gt;. &lt;ul&gt;
&lt;li&gt;If you want to use RoBERTa but find it too large/slow for inference then you should give the models here a go!&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;&amp;#9889;-Playing-the-lottery-with-rewards-and-multiple-languages:-lottery-tickets-in-RL-and-NLP-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual_2020/poster_S1xnXRVFwH.html&quot;&gt;Playing the lottery with rewards and multiple languages: lottery tickets in RL and NLP&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-Playing-the-lottery-with-rewards-and-multiple-languages:-lottery-tickets-in-RL-and-NLP-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;This work is a follow on from &lt;a href=&quot;https://arxiv.org/abs/1803.03635v5&quot;&gt;The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks&lt;/a&gt; from Jonathan Frankle, Michael Carbin at FAIR, who's research codebase has just been released by the way: 

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I just open-sourced my codebase for research on neural network pruning, the Lottery Ticket Hypothesis, and other topics in deep learning.  It&amp;#39;s written in PyTorch and designed to make it easy to add new models, datasets, and experiments. Check it out: &lt;a href=&quot;https://t.co/JyTGT8RRZW&quot;&gt;https://t.co/JyTGT8RRZW&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jonathan Frankle (@jefrankle) &lt;a href=&quot;https://twitter.com/jefrankle/status/1258440816982458368?ref_src=twsrc%5Etfw&quot;&gt;May 7, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/li&gt;
&lt;li&gt;At ICLR 2020 they present how the &lt;a href=&quot;https://towardsdatascience.com/breaking-down-the-lottery-ticket-hypothesis-ca1c053b3e58&quot;&gt;lottery ticket phenomenon&lt;/a&gt;, which previously was only explored for vision models, applies more generally to deep neural networks across NLP and reinforcement learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;They test it with NLP models, LSTMs and Transformer, as well as reinforcement learning models and found that the lottery ticket sub-networks performed better than randomly pruned networks, as was found in their previous work on vision models. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/lottery.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The authors used Iterative Pruning with Late Resetting (aka Late Rewinding):

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;The trick is that the subnetworks don&amp;#39;t always emerge at initialization. Instead, we found that training these subnetworks from an iteration slightly after initialization (between a few iterations and a few epochs) often works much better. We term this technique &amp;quot;late resetting.&amp;quot;&lt;/p&gt;&amp;mdash; Jonathan Frankle (@jefrankle) &lt;a href=&quot;https://twitter.com/jefrankle/status/1103293740465221632?ref_src=twsrc%5Etfw&quot;&gt;March 6, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/li&gt;
&lt;li&gt;Currently the downside to discovering lottery tickets is that they are very computationally expensive to discover. Here the authors trained the models to convergence, before pruning ~20%, reinitializing  and training again. Several cycles of this requires significant computational resources for large models such as transformers and reinforcement learning frameworks. However once a lottery ticket is found it can be trained quickly due to its reduced size whilst still maintaining almost the same performance of the original full network.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;I'd also recommend watching the authors second ICLR 2020 paper, &lt;a href=&quot;https://iclr.cc/virtual/poster_Hkl1iRNFwS.html&quot;&gt;&quot;The Early Phase of Neural Network Training&quot;&lt;/a&gt;, which explored how the &quot;Early Phase&quot; of the network training, i.e. the point at which lottery ticket sub-networks emerge (and the point at which Late Resetting would reset to) was impacted by variations to the input data and weight distributions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;&amp;#9889;-Dynamic-Model-Pruning-with-Feedback-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual_2020/poster_SJem8lSFwB.html&quot;&gt;Dynamic Model Pruning with Feedback&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-Dynamic-Model-Pruning-with-Feedback-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The paper introduces a dynamic way to prune weights (Dynamic Model Pruning with Feedback, or DPF) that allows previously pruned model weights to be re-activated when needed, resulting in lottery-ticket peformance of the pruned models while only needing to be trained once (unlike lottery tickets which need multiple rounds of training)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/dynamic_pruning.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They achieve state-of-the-art top-1 accuracy for pruning on CIFAR-10 and Imagenet for unstructured weight pruning&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;The gradient is &lt;strong&gt;evaluated for the pruned model&lt;/strong&gt; and then &lt;strong&gt;applied to the dense model&lt;/strong&gt;. The binary mask is periodically updated to reallocate the weights. The intuition is that the gradient is used to measure the &quot;error&quot; and then the dense model is used to correct this error
&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/dynamic_pruning2.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Unstructured magnitude pruning was used&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;The authors say that the code will be released in June&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;&amp;#9889;-Once-for-All:-Train-One-Network-and-Specialize-it-for-Efficient-Deployment-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual_2020/poster_HylxE1HKwS.html&quot;&gt;Once for All: Train One Network and Specialize it for Efficient Deployment&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-Once-for-All:-Train-One-Network-and-Specialize-it-for-Efficient-Deployment-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The idea here is that a single large model can be trained the contains a multitude of high performant sub-networks. These sub-networks can be pruned for use in a wide variety of edge device types and sizes &lt;strong&gt;without additional training&lt;/strong&gt;. The author's focussed on training efficient vision models for this paper.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/once_for_all2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This enables strong performance on a wide variety of devices, without incurring the computational expence (and CO2 footprint) of searching for specialised architectures for each device&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/once_for_all3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The key to training this model is a technique called &lt;strong&gt;Progresive Shrinking&lt;/strong&gt; which is a:&lt;blockquote&gt;&lt;p&gt;a generalized pruning method that reduces the model size across many more dimensions than pruning (depth, width, kernel size, and resolution)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/once_for_all_prog_shrink.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They achieved 1.5x lower latency for MobileNet-V3 and 2.6x for EfficientNet in ImageNet mobile setting while maintaining the same accuracy&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Their Code and &lt;strong&gt;50 pre-trained models&lt;/strong&gt; (for many devices &amp;amp; many latency constraints) can be &lt;a href=&quot;https://github.com/mit-han-lab/once-for-all&quot;&gt;found in their gihub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Other-Great-Papers-You-Should-Absolutely-Checkout-&amp;#128175;&quot;&gt;Other Great Papers You Should Absolutely Checkout &amp;#128175;&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Great-Papers-You-Should-Absolutely-Checkout-&amp;#128175;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;There were many other super interesting papers I couldn't cover there, some of my favorites are below&lt;/p&gt;
&lt;h3 id=&quot;Optimisation&quot;&gt;Optimisation&lt;a class=&quot;anchor-link&quot; href=&quot;#Optimisation&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://iclr.cc/virtual_2020/poster_SkgGjRVKDS.html&quot;&gt;Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduces Moving Average Batch Normalization (MABN) for training with small batches&lt;/li&gt;
&lt;li&gt;Restores BatchNorm-like performance when training with small batches, down to bs=1 (BatchNorm tends to suffer when training with small batches) &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/megvii-model/MABN&quot;&gt;Code here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://iclr.cc/virtual_2020/poster_HkgaETNtDB.html&quot;&gt;Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Useful for stabilising training on fine-tuning (BERT for downstream task for example)&lt;/li&gt;
&lt;li&gt;Motivated by DropOut (which is a special case of DropConnect)&lt;/li&gt;
&lt;li&gt;Replaces a randomly selected parameter with a &quot;target&quot; parameter, instead of zero as in DropOut, from a previously memorised state&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/bloodwass/mixout&quot;&gt;Code here&lt;/a&gt;
&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/mixout.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Vision&quot;&gt;Vision&lt;a class=&quot;anchor-link&quot; href=&quot;#Vision&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://iclr.cc/virtual_2020/poster_rkeu30EtvS.html&quot;&gt;Network Deconvolution&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Correlations between pixels and between channels can make image recognition more difficult, the authors propose network deconvolution to solve this&lt;/li&gt;
&lt;li&gt;Achieves impressive performance gains across ResNet, ResNeXt, EfficientNet, VGG (and more) in both image classification and semantic segmentation tasks, &lt;strong&gt;even when BatchNorm is removed&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Network Deconvolution seems to hold promise beyond vision models too:&lt;blockquote&gt;&lt;p&gt;Also, the same deconvolution procedure for 1 × 1 convolutions can be used for non-convolutional layers, which makes it useful for the broader machine learning community.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/yechengxi/deconvolution&quot;&gt;Code here&lt;/a&gt;- Network Deconvolution has also been discussed and implemented in the &lt;a href=&quot;https://forums.fast.ai/t/network-deconvolution-cnns-that-are-more-robust-and-easier-to-train/70412&quot;&gt;fastai forums&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200508_iclr_2/network_deconv.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://iclr.cc/virtual_2020/poster_rJeB36NKvB.html&quot;&gt;How much Position Information Do Convolutional Neural Networks Encode?&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adding zero-padding (widely used already) implicitly delivers positional information and imrproves vision performance&lt;/li&gt;
&lt;li&gt;Deeper models can better encode positional information&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Thanks-for-Reading-&amp;#128515;&quot;&gt;Thanks for Reading &amp;#128515;&lt;a class=&quot;anchor-link&quot; href=&quot;#Thanks-for-Reading-&amp;#128515;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As always, I would love to hear if you have any comments, thoughts or criticisms at &lt;strong&gt;&lt;a href=&quot;www.twitter.com/mcgenergy&quot;&gt;@mcgenergy&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Morgan McGuire</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.ntentional.com/images/iclr_logo.png" /><media:content medium="image" url="https://www.ntentional.com/images/iclr_logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">ICLR 2020: Efficient NLP - Transformers</title><link href="https://www.ntentional.com/papers/nlp/efficient-nlp/transformers/2020/05/05/iclr-hghlights.html" rel="alternate" type="text/html" title="ICLR 2020: Efficient NLP - Transformers" /><published>2020-05-05T00:00:00-05:00</published><updated>2020-05-05T00:00:00-05:00</updated><id>https://www.ntentional.com/papers/nlp/efficient-nlp/transformers/2020/05/05/iclr-hghlights</id><content type="html" xml:base="https://www.ntentional.com/papers/nlp/efficient-nlp/transformers/2020/05/05/iclr-hghlights.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-05-iclr-hghlights.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;I was lucky enough to volunteer and attend (virtual) ICLR 2020. It delivered a huge amount of learning for me and I was fortunate to join some really great discussions.&lt;/p&gt;
&lt;p&gt;Efficient NLP was big focus of many of the papers and here I will focus on a few of the more well known transformer architectures proposed over the past year or so; Reformer, ELECTRA, Lite Transformer and ALBERT. Towards the end of this article I also mention additional ICLR summaries that are worth reading 🙂&lt;/p&gt;
&lt;h3 id=&quot;Note:-ICLR-Videos-Now-Online!&quot;&gt;Note: ICLR Videos Now &lt;a href=&quot;http://iclr.cc/virtual_2020/&quot;&gt;Online&lt;/a&gt;!&lt;a class=&quot;anchor-link&quot; href=&quot;#Note:-ICLR-Videos-Now-Online!&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;All of the ICLR paper talks and slides are now online, I &lt;strong&gt;highly recommend&lt;/strong&gt; watching the 5 to 15minutes videos accompanying each of the papers below for some excellent summaries and additional understanding

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/hashtag/ICLR2020?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#ICLR2020&lt;/a&gt; Public Archive - &lt;a href=&quot;https://t.co/EpXWIK0ujS&quot;&gt;https://t.co/EpXWIK0ujS&lt;/a&gt; &lt;br /&gt;* ~700 short talks with synced slides, papers, and code&lt;br /&gt;* 8 keynotes with moderated QA &lt;br /&gt;* 15 workshops on topics ranging from climate change to AfricaNLP. &lt;a href=&quot;https://t.co/FVX2JJUYVZ&quot;&gt;pic.twitter.com/FVX2JJUYVZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Sasha Rush (@srush_nlp) &lt;a href=&quot;https://twitter.com/srush_nlp/status/1257287875323969537?ref_src=twsrc%5Etfw&quot;&gt;May 4, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Efficient-NLP---Transformers&quot;&gt;Efficient NLP - Transformers&lt;a class=&quot;anchor-link&quot; href=&quot;#Efficient-NLP---Transformers&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;New transformer architectures that promise less compute-intense NLP training, in order of my excitement to use them:&lt;/p&gt;
&lt;h3 id=&quot;&amp;#9889;-Reformer:-The-Efficient-Transformer-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual_2020/poster_rkgNKkHtvB.html&quot;&gt;Reformer: The Efficient Transformer&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-Reformer:-The-Efficient-Transformer-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Reformer enables training on &lt;strong&gt;much longer&lt;/strong&gt; sequences than BERT-like models (e.g. document-length sequences instead of 512 token length sequences) much more efficiently&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Reformer introduces a couple of techniques that improve both time and memory efficiency:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Technique 1: Reversible residual connection layers&lt;/strong&gt; (originally used in computer vision in &lt;a href=&quot;https://ameroyer.github.io/reading-notes/architectures/2019/05/07/the_reversible_residual_network.html&quot;&gt;RevNets&lt;/a&gt;) instead of the standard residual layers improves &lt;strong&gt;memory efficiency:&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200505_iclr_efficient/reformer_rev.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Technique 2: Locality-Sensitive Hashing (LSH)&lt;/strong&gt; based attention replaces dot-product attention (and is much faster) which reduces the &lt;strong&gt;time complexity:&lt;/strong&gt; 
&lt;img src=&quot;/images/copied_from_nb/my_icons/20200505_iclr_efficient/reformer_lsh.png&quot; alt=&quot;&quot; /&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;The 15 minute ICLR paper presentation video linked above really helps better understand these concepts&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/lucidrains/reformer-pytorch&quot;&gt;&lt;strong&gt;A PyTorch Reformer implementation can be found here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;&amp;#9889;-ELECTRA:-Pre-training-Text-Encoders-as-Discriminators-Rather-Than-Generators-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual_2020/poster_r1xMH1BtvB.html&quot;&gt;ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-ELECTRA:-Pre-training-Text-Encoders-as-Discriminators-Rather-Than-Generators-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;ELECTRA brings a couple of novelties, resulting in a much more computationally efficient transformer to train. It is trained with:&lt;ul&gt;
&lt;li&gt;a Generator-Discriminator setup and &lt;/li&gt;
&lt;li&gt;a new pre-training task called Replaced Token Detection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The Generator is trained to replace masked tokens (as per the standard MLM task), the Discriminator then tries to identify the token that has been replaced&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200505_iclr_efficient/electra.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One subtle thing to note is that if the generator happens to generate the correct token then that token is considered &quot;real&quot; instead of &quot;fake&quot; &lt;/li&gt;
&lt;li&gt;ELECTRA-small can be trained on a single V100 GPU (4 days) &lt;/li&gt;
&lt;li&gt;It is slower per epoch than other transformers, but it converges faster resulting in an overall faster training:&lt;blockquote&gt;&lt;p&gt;the model learns from all input tokens instead of just the small masked-out subset, making it more computationally efficient&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Very strong results and it's performance scales up as the architecture is made larger&lt;/li&gt;
&lt;li&gt;Lots more interesting results and experiment discussion can be found in the paper&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://huggingface.co/transformers/model_doc/electra.html?highlight=electra&quot;&gt;&lt;strong&gt;A HuggingFace ELECTRA Implementation is here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;&amp;#9889;-Lite-Transformer-with-Long-Short-Range-Attention-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual_2020/poster_ByeMPlHKPH.html&quot;&gt;Lite Transformer with Long-Short Range Attention&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-Lite-Transformer-with-Long-Short-Range-Attention-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Introduces Long-Short Range Attention (LRSA) which results in a reduction in model computation between 2.5x and 3x compared to original Transformer.
&lt;img src=&quot;/images/copied_from_nb/my_icons/20200505_iclr_efficient/lite_summary.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The new architecture enables 2 different perspectives on the input sequence:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;...one group of heads specializes in the local context modeling (by convolution) while another group specializes in the long-distance relationship modeling (by attention)...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The LSRA architecture and where the attention is focussed can be seen here:&lt;img src=&quot;/images/copied_from_nb/my_icons/20200505_iclr_efficient/lite_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Lite Transformer performs well against the original Transformer for translation, summarisation and language modelling&lt;/li&gt;
&lt;li&gt;One thing I liked is that Lite Transformer looks at performance under mobile-like constraints, defined by the authros as 10M parameters and 1G FLOPs &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/mit-han-lab/lite-transformer&quot;&gt;&lt;strong&gt;Lite Transformer code (PyTorch) is available from the authors here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;&amp;#9889;-ALBERT:-A-Lite-BERT-for-Self-supervised-Learning-of-Language-Representations-&amp;#9889;&quot;&gt;&amp;#9889; &lt;a href=&quot;https://iclr.cc/virtual_2020/poster_H1eA7AEtvS.html&quot;&gt;ALBERT: A Lite BERT for Self-supervised Learning of Language Representations&lt;/a&gt; &amp;#9889;&lt;a class=&quot;anchor-link&quot; href=&quot;#&amp;#9889;-ALBERT:-A-Lite-BERT-for-Self-supervised-Learning-of-Language-Representations-&amp;#9889;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;ALBERT is 18x smaller model than BERT-large and can be trained 1.7x faster while still outperforming it&lt;/li&gt;
&lt;li&gt;The two techniques used to reduce its size are:&lt;ul&gt;
&lt;li&gt;Reduce the vocabulary embedding size; they reduce the matrix size by projecting it to a lower dimension. e.g. an input one-hot encoded matrix of size 30,000 is reduced to a much smaller sized matix which is then used&lt;/li&gt;
&lt;li&gt;Cross-layer parameter sharing; they use the same operations and repeat them multiple times. This helps the parameter size of the network growing as layers as added &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ALBERT uses 3 training tricks to further improve its performance:&lt;ol&gt;
&lt;li&gt;Uses MLM and Sentence Order Prediction (SOP), a self-supervised loss that focuses on modeling inter-sentence coherence&lt;/li&gt;
&lt;li&gt;Does not use dropout (due to the huge amount of data available)&lt;/li&gt;
&lt;li&gt;Uses 10x more data than BERT-Base&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://huggingface.co/transformers/model_doc/albert.html&quot;&gt;&lt;strong&gt;HuggingFace PyTorch ALBERT code can be found here&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200505_iclr_efficient/albert.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;Other-Great-Summaries-to-Read&quot;&gt;Other Great Summaries to Read&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Great-Summaries-to-Read&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Other great summaries from ICLR attendees are below, the Google Doc in Yacine's tweet below gives brief summaries to even more papers that I haven't covered here&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://twitter.com/mstanojevic118/status/1255987903408287745&quot;&gt;Marija Stanojevic on mentorship tips for aspiring ML Researchers&lt;/a&gt;&lt;/strong&gt;, &lt;a href=&quot;https://twitter.com/mstanojevic118&quot;&gt;@mstanojevic118&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://twitter.com/YJernite/status/1256284687242330112&quot;&gt;Yacine Jernite with additional paper summaries&lt;/a&gt;&lt;/strong&gt;, &lt;a href=&quot;https://twitter.com/YJernite&quot;&gt;@YRnite&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.analyticsvidhya.com/blog/2020/05/key-takeaways-iclr-2020/&quot;&gt;Analytics Vidhya with a summary of the event and what the most used opensource tools were&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;To-Close&quot;&gt;To Close&lt;a class=&quot;anchor-link&quot; href=&quot;#To-Close&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Research work on efficient NLP is moving rapidly and it was fascinating to see so many different approaches on display at ICLR this year, myself and my single GPU are super excited to see how fast things will develop this year 😆&lt;/p&gt;
&lt;p&gt;This was also the first ML conference I attended and found the (covid-caused) virtual format to work exceptionally well, my huge congrates to all of the organisers involved in pulling off a massive amount of work in such a short amount of time!&lt;/p&gt;
&lt;p&gt;As always, I would love to hear if you have any comments, thoughts or criticisms at &lt;strong&gt;&lt;a href=&quot;www.twitter.com/mcgenergy&quot;&gt;@mcgenergy&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Morgan McGuire</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.ntentional.com/images/iclr_logo.png" /><media:content medium="image" url="https://www.ntentional.com/images/iclr_logo.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">FastHugs: Language Modelling with Tranformers and Fastai</title><link href="https://www.ntentional.com/nlp/transformers/training%20technique/classification/2020/04/24/fasthugs_language_model.html" rel="alternate" type="text/html" title="FastHugs: Language Modelling with Tranformers and Fastai" /><published>2020-04-24T00:00:00-05:00</published><updated>2020-04-24T00:00:00-05:00</updated><id>https://www.ntentional.com/nlp/transformers/training%20technique/classification/2020/04/24/fasthugs_language_model</id><content type="html" xml:base="https://www.ntentional.com/nlp/transformers/training%20technique/classification/2020/04/24/fasthugs_language_model.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-24-fasthugs_language_model.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This aims to be an end-to-end description with code of how to train a transformer language model using fastai (v2) and HuggingFace, enjoy!&lt;/p&gt;
&lt;h2 id=&quot;TL;DR&quot;&gt;TL;DR&lt;a class=&quot;anchor-link&quot; href=&quot;#TL;DR&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Main interesting bits in this notebook:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Provides full code to train a transformer (RoBERTa) using a Masked Language Model task&lt;/li&gt;
&lt;li&gt;Utilise's many of HuggingFace's tokenizer features within fastai&lt;/li&gt;
&lt;li&gt;Make predictions of masked tokens like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200424_fasthugs_lm/roberta_pred.png&quot; alt=&quot;&quot; title=&quot;RoBERTa&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;Before-we-get-started&quot;&gt;Before we get started&lt;a class=&quot;anchor-link&quot; href=&quot;#Before-we-get-started&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;First off, huge thanks as always to both the Fastai and HuggingFace teams for giving so much back to the community by open-sourcing so much&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For an example of &lt;strong&gt;text sequence classification&lt;/strong&gt; using HuggingFace and fastai, have a look at my previous notebook &lt;a href=&quot;https://github.com/morganmcg1/fasthugs/blob/master/fasthugs_seq_classification.ipynb&quot;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This tutorial is heavily based on HuggingFace's &lt;a href=&quot;https://huggingface.co/blog/how-to-train&quot;&gt;&quot;How to train a new language model from scratch using Transformers and Tokenizers&quot;&lt;/a&gt;  tutorial, I highly recommend checking that out too. I try and highlight throughout where code has been used, borrowed or inspired by HuggingFace's code.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;MLM-Tranform&quot;&gt;MLM Tranform&lt;a class=&quot;anchor-link&quot; href=&quot;#MLM-Tranform&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;I feel the most useful thing in this notebook is the &lt;code&gt;MLMTokensLabels&lt;/code&gt; transform*. This carries out the Masked Language Model task that RoBERTa was originally trained on.&lt;/p&gt;
&lt;p&gt;This will take tokens ids (tokens after the have been numericalized), select a subset and either mask a certain amount of them (for prediction) or replace them with other random token ids (for regularisation). This transform also creates our labels by copying the input token ids and masking the tokens that do &lt;strong&gt;not&lt;/strong&gt; need to be predicted, so that no loss is calculated on them.&lt;/p&gt;
&lt;p&gt;Note the if you wish to train BERT or other transformer language models you will probably need to use a different task, e.g. BERT was trained on 2 tasks simultaneously, MLM and Next Sentence Prediction (NSP). Have a look at any blog posts or arxiv paper of the transformer of interest to find which task was used to pretrain it.&lt;/p&gt;
&lt;p&gt;*This transform code is a re-write of the &lt;code&gt;mask_tokens&lt;/code&gt; function used in HugginFace's tutorial, &lt;a href=&quot;https://github.com/huggingface/transformers/blob/a21d4fa410dc3b4c62f93aa0e6bbe4b75a101ee9/examples/run_language_modeling.py#L66&quot;&gt;code here&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Pretraining-+-Fine-Tuning:&quot;&gt;Pretraining + Fine-Tuning:&lt;a class=&quot;anchor-link&quot; href=&quot;#Pretraining-+-Fine-Tuning:&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As shown in ULMFit, MultiFiT, and elsewhere, you will get better results on your downstream task if you first fine-tune your pretrained model with the text of the same domain as your pretrained task. e.g. training an IMDB movie review classifier who's language model was trained on wikipedia text.

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;1/ Really excited about this one! &amp;quot;Don&amp;#39;t Stop Pretraining: Adapt Language Models to Domains and Tasks&amp;quot; is live! With &lt;a href=&quot;https://twitter.com/anmarasovic?ref_src=twsrc%5Etfw&quot;&gt;@anmarasovic&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/swabhz?ref_src=twsrc%5Etfw&quot;&gt;@swabhz&lt;/a&gt; , &lt;a href=&quot;https://twitter.com/kylelostat?ref_src=twsrc%5Etfw&quot;&gt;@kylelostat&lt;/a&gt; , &lt;a href=&quot;https://twitter.com/i_beltagy?ref_src=twsrc%5Etfw&quot;&gt;@i_beltagy&lt;/a&gt; , Doug Downey, and &lt;a href=&quot;https://twitter.com/nlpnoah?ref_src=twsrc%5Etfw&quot;&gt;@nlpnoah&lt;/a&gt;, to appear at ACL2020. &lt;br /&gt;Paper: &lt;a href=&quot;https://t.co/hVbSQYnclk&quot;&gt;https://t.co/hVbSQYnclk&lt;/a&gt; &lt;br /&gt;Code: &lt;a href=&quot;https://t.co/7wKgE1mUme&quot;&gt;https://t.co/7wKgE1mUme&lt;/a&gt;&lt;/p&gt;&amp;mdash; Suchin Gururangan (@ssgrn) &lt;a href=&quot;https://twitter.com/ssgrn/status/1253498613558243328?ref_src=twsrc%5Etfw&quot;&gt;April 24, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;h2 id=&quot;Using-a-Custom-Tokenizer?&quot;&gt;Using a Custom Tokenizer?&lt;a class=&quot;anchor-link&quot; href=&quot;#Using-a-Custom-Tokenizer?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This code has not been tested using a custom tokenizer. You may want to do so if your text is very specific to a certain domain. If so then you'll have to add a number of attributes to your tokenzier to be able to use the code here. I really recommend the &lt;a href=&quot;https://huggingface.co/blog/how-to-train&quot;&gt;HuggingFace language model tutorial linked above&lt;/a&gt; for an example of training your own tokenizer with your own dataset&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Data&quot;&gt;Data&lt;a class=&quot;anchor-link&quot; href=&quot;#Data&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We'll use the &lt;code&gt;IMDB_SAMPLE&lt;/code&gt; here, pretending we are fine-tuning our transformer model before doing sentiment classification on IMDB. If you are pretraining a language model from scratch you'd aim to use a larger, more generic source like a wikipedia dataset. fastai have the full &lt;code&gt;WikiText103&lt;/code&gt; (100 million tokens) dataset available for easy download here if you'd like to train an enligh language model from scratch:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;path = untar_data(URLs.WIKITEXT)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;HuggingFace-Auto-Classes&quot;&gt;HuggingFace Auto Classes&lt;a class=&quot;anchor-link&quot; href=&quot;#HuggingFace-Auto-Classes&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;HuggingFace have a numer of useful &lt;a href=&quot;https://huggingface.co/transformers/model_doc/auto.html&quot;&gt;&quot;Auto&quot; classes&lt;/a&gt; that enable you to create different models and tokenizers by changing just the model name.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AutoModelWithLMHead&lt;/code&gt; will define our Language model for us. This can either be a pretrained model or a randomly initialised model&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AutoTokenizer&lt;/code&gt; will load our tokenizer and enable us grab our vocab&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AutoConfig&lt;/code&gt; will define the model architecture and settings, note that we use the pretrained config here for ease of use, but one can easily modify this config if needed&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model_name&lt;/code&gt; is the model architecture (and optionally model weights) you'd like to use.&lt;ul&gt;
&lt;li&gt;Language Models tested so far with this notebook: &lt;code&gt;roberta-base&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;You can find all of HuggingFace's models at &lt;a href=&quot;https://huggingface.co/models&quot;&gt;https://huggingface.co/models&lt;/a&gt;, most, but not all of them are supported by &lt;code&gt;AutoModel&lt;/code&gt;,&lt;code&gt;AutoConfig&lt;/code&gt; and &lt;code&gt;AutoTokenizer&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can now easily call whichever transformer we like as below:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta-base&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoModelWithLMHead&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoConfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;HuggingFace-Tokenizer-&amp;amp;-Vocab&quot;&gt;HuggingFace Tokenizer &amp;amp; Vocab&lt;a class=&quot;anchor-link&quot; href=&quot;#HuggingFace-Tokenizer-&amp;amp;-Vocab&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We use &lt;code&gt;AutoTokenizer&lt;/code&gt; to generate our pretrained tokenizer. HuggingFace's &lt;code&gt;get_vocab&lt;/code&gt; returns a &lt;code&gt;token : index&lt;/code&gt; dict however Fastai expects &lt;code&gt;vocab&lt;/code&gt; to be a list. Therefore we need to convert this dict to a list to be able to use it in fastai&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tokenizer_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])]&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Tokenizer &amp;quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;vm&quot;&gt;__class__&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;quot; vocab length is : &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;Tokenizer &amp;#34;&amp;lt;class &amp;#39;transformers.tokenization_roberta.RobertaTokenizer&amp;#39;&amp;gt;&amp;#34; vocab length is : 50265
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Special-Tokens&quot;&gt;Special Tokens&lt;a class=&quot;anchor-link&quot; href=&quot;#Special-Tokens&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Its always good to know what special tokens your tokenizer takes, lets have a look:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;special_tokens_map&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;{&amp;#39;bos_token&amp;#39;: &amp;#39;&amp;lt;s&amp;gt;&amp;#39;,
 &amp;#39;eos_token&amp;#39;: &amp;#39;&amp;lt;/s&amp;gt;&amp;#39;,
 &amp;#39;unk_token&amp;#39;: &amp;#39;&amp;lt;unk&amp;gt;&amp;#39;,
 &amp;#39;sep_token&amp;#39;: &amp;#39;&amp;lt;/s&amp;gt;&amp;#39;,
 &amp;#39;pad_token&amp;#39;: &amp;#39;&amp;lt;pad&amp;gt;&amp;#39;,
 &amp;#39;cls_token&amp;#39;: &amp;#39;&amp;lt;s&amp;gt;&amp;#39;,
 &amp;#39;mask_token&amp;#39;: &amp;#39;&amp;lt;mask&amp;gt;&amp;#39;}&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;FastHugs-Tokenizer&quot;&gt;FastHugs Tokenizer&lt;a class=&quot;anchor-link&quot; href=&quot;#FastHugs-Tokenizer&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This tokenizer wrapper is initialised with the pretrained HF tokenizer, you can also specify the max_seq_len if you want longer/shorter sequences. Given text it returns tokens and adds separator tokens depending on the model type being used.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FastHugsTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot; &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        transformer_tokenizer : takes the tokenizer that has been loaded from the tokenizer class&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        model_name : model type set by the user&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        max_seq_len : override default sequence length, typically 512 for bert-like models.&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                           `transformer_tokenizer.max_len_single_sentence` and `transformer_tokenizer.max_len_sentences_pair` &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                           both account for the need to add additional special tokens, i.e. for RoBERTa-base &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                           max_len_single_sentence==510, leaving space for the 2 additional special tokens &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;                           to be added for the model&amp;#39;s default 512 positional embeddings&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        pair : whether a single sentence (sequence) or pair of sentences are used&lt;/span&gt;

&lt;span class=&quot;sd&quot;&gt;        Returns:&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;            - Tokenized text, up to the max sequence length set by the user or the tokenzier default&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_sentences_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;WARNING: max_seq_len needs to be less than or equal to transformer_tokenizer.max_len_sentences_pair&amp;#39;&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_single_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;WARNING: max_seq_len needs to be less than or equal to transformer_tokenizer.max_len_single_sentence&amp;#39;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_sentences_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
                &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_single_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;do_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Returns tokenized text, adds prefix space if needed, limits the maximum sequence length&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta&amp;#39;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add_prefix_space&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;de_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Return string from tokens&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert_tokens_to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__call__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;do_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;The-Fastai-bit&quot;&gt;The Fastai bit&lt;a class=&quot;anchor-link&quot; href=&quot;#The-Fastai-bit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;fasthugstok-and-our-tok_fn&quot;&gt;&lt;code&gt;fasthugstok&lt;/code&gt; and our &lt;code&gt;tok_fn&lt;/code&gt;&lt;a class=&quot;anchor-link&quot; href=&quot;#fasthugstok-and-our-tok_fn&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Lets incorporate the &lt;code&gt;tokenizer&lt;/code&gt; from HuggingFace into fastai-v2's framework by specifying a function called &lt;code&gt;fasthugstok&lt;/code&gt; that we can then pass on to &lt;code&gt;Tokenizer.from_df&lt;/code&gt;. (Note &lt;code&gt;.from_df&lt;/code&gt; is the only method I have tested)&lt;/p&gt;
&lt;h4 id=&quot;Max-Seqence-Length&quot;&gt;Max Seqence Length&lt;a class=&quot;anchor-link&quot; href=&quot;#Max-Seqence-Length&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;code&gt;max_seq_len&lt;/code&gt; is the longest sequece our tokenizer will output. We can also the max sequence length for the tokenizer by changing &lt;code&gt;max_seq_len&lt;/code&gt;. It uses the tokenizer's default, typically &lt;code&gt;512&lt;/code&gt;. &lt;code&gt;1024&lt;/code&gt; or even &lt;code&gt;2048&lt;/code&gt; can also be used depending on your GPU memory. Note when using pretrained models you won't be able to use a &lt;code&gt;max_seq_len&lt;/code&gt; larger than the default.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fasthugstok&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FastHugsTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                      &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We create a &lt;code&gt;MLMTokenizer&lt;/code&gt; class which inherits from fastai's &lt;code&gt;Tokenizer&lt;/code&gt; in order to fully decode&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MLMTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lengths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lengths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_detokenize1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;de_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TitledStr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_detokenize1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Set up fastai's &lt;code&gt;Tokenizer.from_df&lt;/code&gt;, we pass &lt;code&gt;rules=[fix_html]&lt;/code&gt; to clean up some of HTML messiness in our text. If you do not want any rules then you sould pass &lt;code&gt;rules=[]&lt;/code&gt; to override fastai's default text processing rules&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MLMTokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_cols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_col_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fasthugstok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                     &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fix_html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;post_rules&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;[&amp;lt;function fastai2.text.core.fix_html(x)&amp;gt;]&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Add-Special-Tokens&quot;&gt;Add Special Tokens&lt;a class=&quot;anchor-link&quot; href=&quot;#Add-Special-Tokens&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;BERT-like transformers require special tokens to be added to the sequence, depending on the task, so we need a transform for those too&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AddSpecialTokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Add special token_ids to the numericalized tokens for Sequence Classification&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TensorText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_inputs_with_special_tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Create-MLM-Dataset&quot;&gt;Create MLM Dataset&lt;a class=&quot;anchor-link&quot; href=&quot;#Create-MLM-Dataset&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MLMTokensLabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        MLM task&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        - Select subset of input token ids, given by `mlm_probability`&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        - Mask a subset of these, `mask_token_prob`&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        - Replace half of the first subset with random tokens&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        - This code most comes from the `mask_tokens` function here https://github.com/huggingface/transformers/blob/a21d4fa410dc3b4c62f93aa0e6bbe4b75a101ee9/examples/run_language_modeling.py#L66&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        Returns: input ids and labels&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mlm_probability&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_token_prob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mlm_probability&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token_prob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mlm_probability&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_token_prob&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_gen_probability_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# We sample a few tokens in each sequence for masked-LM training (with probability mlm_probability, defaults to 0.15 in Bert/RoBERTa)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mlm_probability&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;special_tokens_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_special_tokens_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;already_has_special_tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_fill_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;special_tokens_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_pad_token&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;padding_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_fill_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_replace_with_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# for `mask_token_prob`% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert_tokens_to_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_replace_with_other&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 1-`mask_token_prob`)/210% of the time, we replace masked input tokens with random word&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;indices_random&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;random_words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices_random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices_random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;ne&quot;&gt;ValueError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;This tokenizer does not have a mask token which is necessary for masked language modeling.&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Get probability of whether a token will be masked&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_gen_probability_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Create random mask indices according to probability matrix&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probability_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Mask the labels for indices that are NOT masked, we only compute loss on masked tokens&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;  
        
        &lt;span class=&quot;c1&quot;&gt;# Randomly replace with mask token&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_replace_with_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Randomly replace with mask token&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_replace_with_other&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_replaced&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# The rest of the time (10% of the time) we keep the masked input tokens unchanged&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We change &lt;code&gt;decodes&lt;/code&gt; in our &lt;code&gt;Numericalize&lt;/code&gt; class to deal with the &lt;code&gt;&amp;lt;loss_mask&amp;gt;&lt;/code&gt; tokens&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# collapse&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@Numericalize&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;Add the ability to parse masks for the loss function, set as `-100`&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tmp_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tmp_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;loss_mask&amp;gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tmp_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PAD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;And we modify &lt;code&gt;Datasets&lt;/code&gt; so as to not wrap out tuple in another tuple&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# collapse&lt;/span&gt;
&lt;span class=&quot;nd&quot;&gt;@delegates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Doesn&amp;#39;t create a tuple in __getitem__ as x is already a tuple&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_inp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# same as Datasets.__getitem__ but not wrapped in a tuple&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tl&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_indexer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Our dataset is now ready to be created, lets look at an some of our (x,y) that will be passed to the model. When &lt;code&gt;-100&lt;/code&gt; is passed to our loss function (&lt;code&gt;nn.CrossEntropyLoss&lt;/code&gt;) it will be ignored in the calculation. Our model will also ignore any padding tokens (usually defined as &lt;code&gt;1&lt;/code&gt;) when passed to it.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ColSplitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attrgetter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Numericalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
      &lt;span class=&quot;n&quot;&gt;AddSpecialTokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MLMTokensLabels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SortedDL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(tensor([    0,  1890,    12,  5225, 24320,    12,  8494, 18421, 50264,   328,
         14938,  1774,   630,    75,   190,   356,    69, 50264, 32819,   784]),
 tensor([ -100,  -100,  -100,  5225,  -100,  -100,  -100, 18421,  -100,  -100,
          -100,  -100,  -100,    75,  -100,  -100,  -100,  4505,  -100,   784]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Dataloader&quot;&gt;Dataloader&lt;a class=&quot;anchor-link&quot; href=&quot;#Dataloader&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Padding&quot;&gt;Padding&lt;a class=&quot;anchor-link&quot; href=&quot;#Padding&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We need to make sure our padding is done correctly as some transformer models prefer padding on the left while others prefer it on the right. &lt;code&gt;tokenizer.padding_side&lt;/code&gt; will tell us which side is correct. e.g., BERT, Roberta prefers padding to the right, so we set &lt;code&gt;pad_first=False&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pad_mlm_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backwards&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Function that collect `samples` and adds padding, modified `max_len_l` in fastai&amp;#39;s `pad_input`&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#max_len_l = ifnone(max_seq_len, pad_fields.map(lambda f: max([len(s[f]) for s in samples])))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;max_len_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backwards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;## Added this line too, removes tuple if present&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#TODO: remove items if L.index is fixed&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sl&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_idx&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backwards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;retain_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idxx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idxx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transformer_mlm_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;Uses `pad_fields=[0,1]` to pad both input and label&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_side&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;right&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_mlm_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                   &lt;span class=&quot;n&quot;&gt;pad_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformer_mlm_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataloaders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;before_batch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h4 id=&quot;Check-our-batch&quot;&gt;Check our batch&lt;a class=&quot;anchor-link&quot; href=&quot;#Check-our-batch&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;We can see our special RoBERTa tokens (&lt;code&gt;'&amp;lt;s&amp;gt;'&lt;/code&gt;, &lt;code&gt;'&amp;lt;/s&amp;gt;'&lt;/code&gt;), which translate to &lt;code&gt;0, 2&lt;/code&gt; in its vocab, have been added to the start and end of each sequence in the batch. Your can look at these indices in &lt;code&gt;tokenizer.get_vocab()&lt;/code&gt; to confirm this. We can also see that most of the tokens in our target (&lt;code&gt;text_&lt;/code&gt;) are masked out as we only want to calculate the loss on the ~15% of the &lt;code&gt;text&lt;/code&gt; tokens that have been masked.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(torch.Size([4, 512]), torch.Size([4, 512]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
      &lt;th&gt;text_&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I&amp;lt;mask&amp;gt; fortunate enough to meet&amp;lt;mask&amp;gt; Pal segregatedand still have my DS:TMlishing&amp;lt;mask&amp;gt; autographed by&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; at a convention shortly&amp;lt;mask&amp;gt; the release, and asked him why he chose to do the film &quot;camp&quot;. Before&amp;lt;mask&amp;gt; could answer, two studio flacks intercepted and lectured me on how the studio &quot;knew best&quot; and how &quot;no one will take such&amp;lt;mask&amp;gt; film seriously&quot;. I had been reading the Bantam reprints for&amp;lt;mask&amp;gt; couple of years thanks&amp;lt;mask&amp;gt; a&amp;lt;mask&amp;gt; (ComiCon attendees of the 1970s will recall 357hawk and his band? I was in&amp;lt;mask&amp;gt; couple&amp;lt;mask&amp;gt; years of that withnd), and had higher hopes than what we&amp;lt;mask&amp;gt;.&amp;lt;mask&amp;gt;\nThe flacks insisted that no high adventure would ever be&amp;lt;mask&amp;gt; seriously, and so doing 'camp&amp;lt;mask&amp;gt; was the&amp;lt;mask&amp;gt; way. Several other fans jumped in gap my&amp;lt;mask&amp;gt;, with Pal listening as best he could. At the end of the little event, Pal&amp;lt;mask&amp;gt; up to&amp;lt;mask&amp;gt; and apologized,&amp;lt;mask&amp;gt; he could have done more and better.\n\nSTAR WARS put the lie to&lt;/td&gt;
      &lt;td&gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; was&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; George&amp;lt;loss_mask&amp;gt; (&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;OB poster&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; him)&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; after&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; he&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; &quot;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt; friend&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Black&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; him&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; hopes&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; got&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; done&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; only&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; on&amp;lt;loss_mask&amp;gt; side&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; came&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; us&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; wishing&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;,&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'s&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; that&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; it&amp;lt;loss_mask&amp;gt;'t&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;,&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; rating as&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt; destroying the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; still&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; have&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; we&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;hero&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;, there&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; second&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'s&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; serious&amp;lt;loss_mask&amp;gt; Yes&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; And&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;sheet&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; leaping&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; bronze&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; tie&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;AV&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Next&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; If&amp;lt;loss_mask&amp;gt; knows&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; George&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; San&amp;lt;loss_mask&amp;gt; for the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt;&amp;lt;mask&amp;gt; is another one of those 'humans vs insects/eco-horror' features; a theme that was popular in the late 70's.&amp;lt;mask&amp;gt; you can't really call it horror. There's zero suspense and no&amp;lt;mask&amp;gt; events.&amp;lt;mask&amp;gt; other words: this movie&amp;lt;mask&amp;gt; pretty lame. It's not that it&amp;lt;mask&amp;gt; really bad or&amp;lt;mask&amp;gt;; it's just very boring. A construction site near&amp;lt;mask&amp;gt; hotel uncovers a big nest of&amp;lt;mask&amp;gt;. Later on we learn that, probably due to&amp;lt;mask&amp;gt; sorts&amp;lt;mask&amp;gt; pesticides Lounge in the past, their&amp;lt;mask&amp;gt; became poisonous. Some people get bitten and rushed to&amp;lt;mask&amp;gt; hospital and it takes ages for&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; Vanity the&amp;lt;mask&amp;gt; to figure out what's going on.&amp;lt;mask&amp;gt; Foxworth figures&amp;lt;mask&amp;gt; out first and then you can&amp;lt;mask&amp;gt; him go berserk with a digging machine for what seems like several hours.&amp;lt;mask&amp;gt; they&amp;lt;mask&amp;gt; in the house, waiting&amp;lt;mask&amp;gt; get rescued. And, man, you should see all the efforts they make for&amp;lt;mask&amp;gt; them.&amp;lt;mask&amp;gt; won't spoil too much, but at&amp;lt;mask&amp;gt; point they even use a big&amp;lt;mask&amp;gt;. All the&lt;/td&gt;
      &lt;td&gt;&amp;lt;loss_mask&amp;gt; This&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Only&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; gruesome&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; In&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; is&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'s&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; something&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; ants&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; different&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt; used&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; bite&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the residents of&amp;lt;loss_mask&amp;gt; hospital&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Robert&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; it&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; see&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Then&amp;lt;loss_mask&amp;gt; flee&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; all&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; rescuing&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; I&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; one&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; helicopter&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; this&amp;lt;loss_mask&amp;gt; I&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; thinking&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; you&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; on&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; building&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; lots of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; are shown&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movie&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Ant&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; garbage&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; straw&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; ants&amp;lt;loss_mask&amp;gt; wider shots&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; designers&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; near&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; do&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; It&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; as&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; IT&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;EN&amp;lt;loss_mask&amp;gt; AT&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; my&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; title&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;K&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; MAN&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; have&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;for&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'ll&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Now&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;,&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; The&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; saw no fewer than 3 filmed productions&amp;lt;mask&amp;gt; H. G. Wells' great novel, &quot;War of&amp;lt;mask&amp;gt; Worlds&quot;. This&amp;lt;mask&amp;gt; perhaps the least well-known and very probably the best of&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; No other&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; W&amp;lt;mask&amp;gt;W has ever attempted not only to present the story very much as Wells wrote&amp;lt;mask&amp;gt;, but also Burton create the atmosphere of the time&amp;lt;mask&amp;gt; which it was supposed to take place: the last year of&amp;lt;mask&amp;gt; 19th Century, 1900  using Wells' original setting, in and near Woking&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt;.\n\nIMDb&amp;lt;mask&amp;gt; unfFlyingly to what they regard as &quot;spoilers&quot;. That might apply&amp;lt;mask&amp;gt; some&amp;lt;mask&amp;gt;, where the ending might actually be a&amp;lt;mask&amp;gt;, but with regard to one of the most famous novels in&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt;, it seems positively silly. I have&amp;lt;mask&amp;gt; sympathy&amp;lt;mask&amp;gt; people who have neglected to&amp;lt;mask&amp;gt; one&amp;lt;mask&amp;gt; the seminal works&amp;lt;mask&amp;gt; English literature,&amp;lt;mask&amp;gt; let's get right to the chase. The aliens are destroyed through catching an Earth disease,&amp;lt;mask&amp;gt; hits&amp;lt;mask&amp;gt; have no immunity. If that wo a spoiler, so be&lt;/td&gt;
      &lt;td&gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; year 2005&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; is&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; them.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; version of&amp;lt;loss_mask&amp;gt;ot&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; it&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;, England&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; seems unfriend&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt; films&amp;lt;loss_mask&amp;gt; where&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; might&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; surprise&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the world&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; have no&amp;lt;loss_mask&amp;gt; for&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; read&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; so&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; against which they&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'s&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; other&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; 1953 classic&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;' plot&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;, is&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; �&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; way&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; off due to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Century&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;ides&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; film&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; some&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; an&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; old&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; than&amp;lt;loss_mask&amp;gt;).&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; are typical of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;'t&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;,&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;/white and&amp;lt;loss_mask&amp;gt; on&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; as&amp;lt;loss_mask&amp;gt; described them&amp;lt;loss_mask&amp;gt; have a more&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;feel&quot;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; destruction&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; more&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; period&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; particularly&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; or brilliant&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; facial&amp;lt;loss_mask&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt;&amp;lt;mask&amp;gt; watched Grend&amp;lt;mask&amp;gt; the&amp;lt;mask&amp;gt; night and am compelled&amp;lt;mask&amp;gt; evangelical&amp;lt;mask&amp;gt; a Public Service Announcement.\n\nGrendel is another version of&amp;lt;mask&amp;gt;owulf, the thousand- resulted-&amp;lt;mask&amp;gt; Anglo-Saxon epic poem.&amp;lt;mask&amp;gt; SciFi channeluture a growing catalog of inoffensive&amp;lt;mask&amp;gt; uninterestingxs,&amp;lt;mask&amp;gt; the previews promised an&amp;lt;mask&amp;gt;authentic low-budget mini-epic, but this one refused to&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; switch channels.&amp;lt;mask&amp;gt; was staggeringly, overwhelmingly, bad&amp;lt;mask&amp;gt; I watched in fascination and horror at the train wreck you&amp;lt;mask&amp;gt;'t tear your eyes away from&amp;lt;mask&amp;gt; I reached for a notepad and managed to capture part of what I was seeing.&amp;lt;mask&amp;gt; following may contain spoilers or might just save your sanity&amp;lt;mask&amp;gt; You've been warned.\n\n- Just to&amp;lt;mask&amp;gt; it over with, Beow&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; warriors wore horned&amp;lt;mask&amp;gt;.&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt;ial issue compared to what came after. It also appears that the helmets were in a bin and handed&amp;lt;mask&amp;gt; whichever actor wandered by next. Fit,&amp;lt;mask&amp;gt; and function&amp;lt;mask&amp;gt; apparently irrelevant.\n\n- Marina Sirtis&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt; been blackmailed into doing the&amp;lt;mask&amp;gt; by&amp;lt;mask&amp;gt; Ringling Brothers, Barnum and&amp;lt;mask&amp;gt;&amp;lt;mask&amp;gt;.&amp;lt;mask&amp;gt; managed to avoid a red rubber nose, but the&lt;/td&gt;
      &lt;td&gt;&amp;lt;loss_mask&amp;gt; I&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;el&amp;lt;loss_mask&amp;gt; other&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to put together&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Be&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;year&amp;lt;loss_mask&amp;gt;old&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; The&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; has&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; and&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movies&amp;lt;loss_mask&amp;gt; and&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; in&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; let me&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;. It&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; couldn&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; The&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; contain&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; save&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; get&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;ulf's&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; helmets&amp;lt;loss_mask&amp;gt; Triv&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt; actor&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; appearance&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; were&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; had obviously&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movie&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Bailey circus&amp;lt;loss_mask&amp;gt; She&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; Ben&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; not&amp;lt;loss_mask&amp;gt; be&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; H&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; must have&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; film&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; hadn&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; to&amp;lt;loss_mask&amp;gt; him&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; facilitate&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; hairst&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; of&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; sideburn&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; and&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;.&amp;lt;loss_mask&amp;gt; prove&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; a&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;-&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movie&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; this&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;shaped&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;-&amp;lt;loss_mask&amp;gt; and&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; tradition&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt; volume&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;\n&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; unintended focus&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; movie&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; with&amp;lt;loss_mask&amp;gt; bolts&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; recoil&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt; the&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&amp;lt;loss_mask&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Model&quot;&gt;Model&lt;a class=&quot;anchor-link&quot; href=&quot;#Model&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Our model can be instantiated with either pretrained or random weights. We also need to be careful to pass the model the &lt;code&gt;attention_mask&lt;/code&gt; so that the model ignores padding tokens when training.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LMModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;hasattr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;module&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize_token_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# only return the prediction_scores (and not hidden states and attention)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Pretrained-Language-Model&quot;&gt;Pretrained Language Model&lt;a class=&quot;anchor-link&quot; href=&quot;#Pretrained-Language-Model&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Lets fine-tune our pretrained Language Model. We would typically do this before training the model on our specific text. Note that here we are not training the language model head before we train the full model, but we could do so if we created a splitter and passed it to our learner&lt;/p&gt;
&lt;p&gt;To load the pretrained HuggingFace model just use &lt;code&gt;pretrained=True&lt;/code&gt; when calling your model:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LMModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                  &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Training&quot;&gt;Training&lt;a class=&quot;anchor-link&quot; href=&quot;#Training&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;From here we train our model as usual using fastai. Note that we use &lt;code&gt;Perplexity&lt;/code&gt; as our metric as it is a good measure of how well a language model is training&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decouple_wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CrossEntropyLossFlat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#splitter=model_splitter, &lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Perplexity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We check our learning rate finder&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;suggestions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stop_div&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SuggestedLRs(lr_min=0.025118863582611083, lr_steep=0.2089296132326126)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;We do some training&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: left;&quot;&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;perplexity&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;13.052832&lt;/td&gt;
      &lt;td&gt;11.317341&lt;/td&gt;
      &lt;td&gt;0.052725&lt;/td&gt;
      &lt;td&gt;82235.375000&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;8.539399&lt;/td&gt;
      &lt;td&gt;5.935386&lt;/td&gt;
      &lt;td&gt;0.049121&lt;/td&gt;
      &lt;td&gt;378.185822&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.660586&lt;/td&gt;
      &lt;td&gt;0.785814&lt;/td&gt;
      &lt;td&gt;0.493350&lt;/td&gt;
      &lt;td&gt;2.194192&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0.731211&lt;/td&gt;
      &lt;td&gt;0.768679&lt;/td&gt;
      &lt;td&gt;0.493125&lt;/td&gt;
      &lt;td&gt;2.156916&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0.732979&lt;/td&gt;
      &lt;td&gt;0.772890&lt;/td&gt;
      &lt;td&gt;0.492373&lt;/td&gt;
      &lt;td&gt;2.166016&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;0.681202&lt;/td&gt;
      &lt;td&gt;0.695503&lt;/td&gt;
      &lt;td&gt;0.493711&lt;/td&gt;
      &lt;td&gt;2.004716&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;0.660206&lt;/td&gt;
      &lt;td&gt;0.681334&lt;/td&gt;
      &lt;td&gt;0.494063&lt;/td&gt;
      &lt;td&gt;1.976512&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;0.469388&lt;/td&gt;
      &lt;td&gt;0.641964&lt;/td&gt;
      &lt;td&gt;0.495615&lt;/td&gt;
      &lt;td&gt;1.900209&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;0.512519&lt;/td&gt;
      &lt;td&gt;0.612524&lt;/td&gt;
      &lt;td&gt;0.494834&lt;/td&gt;
      &lt;td&gt;1.845082&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0.545736&lt;/td&gt;
      &lt;td&gt;0.625833&lt;/td&gt;
      &lt;td&gt;0.495205&lt;/td&gt;
      &lt;td&gt;1.869804&lt;/td&gt;
      &lt;td&gt;00:33&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;And we see how our loss progressed&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Lets-Look-at-the-model's-predictions&quot;&gt;Lets Look at the model's predictions&lt;a class=&quot;anchor-link&quot; href=&quot;#Lets-Look-at-the-model's-predictions&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Manually checking how well our model makes predictions for masked tokens is a simple way to see how it is training&lt;/p&gt;
&lt;p&gt;Here function &lt;code&gt;get_mask_pred&lt;/code&gt; takes masked string given by the user and returns the &lt;code&gt;topk&lt;/code&gt; predictions given by the model for that masked token. With it we can sanity check that our model has learned something useful!&lt;/p&gt;
&lt;p&gt;*Note that &lt;code&gt;get_mask_pred&lt;/code&gt; is mostly code from &lt;code&gt;FillMaskPipeline&lt;/code&gt; in HuggingFace's Transformers repo, full credit to them!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Code lightly modified from `FillMaskPipeline` in the HuggingFace Transformers library&amp;quot;&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;aa&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bb&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Numericalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;aa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AddSpecialTokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;outs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;masked_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nonzero&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;probs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vv&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vv&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;word&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;Input text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;score&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;token&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sequence&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;word&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;score&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;token&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;sequence&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)})&lt;/span&gt; 

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Here we can input our own masked sentence and see how the model does. Note that even without fine-tuning the performance below will still be very strong as the pretrained RoBERTa model is very strong.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;I was walking to &amp;lt;mask&amp;gt; when I came across a cat on the road&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to&amp;lt;mask&amp;gt; when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;school&lt;/td&gt;
      &lt;td&gt;0.791473&lt;/td&gt;
      &lt;td&gt;334&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to school when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;church&lt;/td&gt;
      &lt;td&gt;0.068957&lt;/td&gt;
      &lt;td&gt;2352&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to church when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;work&lt;/td&gt;
      &lt;td&gt;0.068007&lt;/td&gt;
      &lt;td&gt;173&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to work when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;breakfast&lt;/td&gt;
      &lt;td&gt;0.007202&lt;/td&gt;
      &lt;td&gt;7080&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to breakfast when I came across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;strong&gt;Not bad at all!&lt;/strong&gt; Now lets see how it does on a movie review, lets look at an example from our validation set. We mask the word &lt;code&gt;might&lt;/code&gt; from the first sentence of the reivew, &lt;code&gt;... shows what might happen...&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# our validation split starts at index 800&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;mask&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what&amp;lt;mask&amp;gt; happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;would&lt;/td&gt;
      &lt;td&gt;0.809723&lt;/td&gt;
      &lt;td&gt;74&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what would happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;might&lt;/td&gt;
      &lt;td&gt;0.131539&lt;/td&gt;
      &lt;td&gt;429&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;could&lt;/td&gt;
      &lt;td&gt;0.042638&lt;/td&gt;
      &lt;td&gt;115&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what could happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;will&lt;/td&gt;
      &lt;td&gt;0.009556&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what will happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Boom, pretty darn good! Lets try the same example, replacing &lt;code&gt;ancient&lt;/code&gt; in &lt;code&gt;discovery of ancient documents&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# our validation split starts at index 800&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;mask&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of&amp;lt;mask&amp;gt; documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;historical&lt;/td&gt;
      &lt;td&gt;0.585666&lt;/td&gt;
      &lt;td&gt;4566&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of historical documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;old&lt;/td&gt;
      &lt;td&gt;0.086817&lt;/td&gt;
      &lt;td&gt;793&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of old documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;obscure&lt;/td&gt;
      &lt;td&gt;0.040825&lt;/td&gt;
      &lt;td&gt;23732&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of obscure documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;ancient&lt;/td&gt;
      &lt;td&gt;0.035504&lt;/td&gt;
      &lt;td&gt;8178&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Again, pretty solid predictions!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Train-a-Language-Model-from-Scratch!&quot;&gt;Train a Language Model from Scratch!&lt;a class=&quot;anchor-link&quot; href=&quot;#Train-a-Language-Model-from-Scratch!&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We can follow the same procedure to train a language model from scratch by using &lt;code&gt;pretrained=False&lt;/code&gt; when seeing up our model&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LMModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_model_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                  &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decouple_wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CrossEntropyLossFlat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Perplexity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Training&quot;&gt;Training&lt;a class=&quot;anchor-link&quot; href=&quot;#Training&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Untrained&quot;&gt;Untrained&lt;a class=&quot;anchor-link&quot; href=&quot;#Untrained&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Again, lets look at the predictions:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;I was walking to &amp;lt;mask&amp;gt; when I cam across a cat on the road&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to&amp;lt;mask&amp;gt; when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;the&lt;/td&gt;
      &lt;td&gt;0.037963&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to the when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;0.036504&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to. when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;,&lt;/td&gt;
      &lt;td&gt;0.033266&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to, when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;of&lt;/td&gt;
      &lt;td&gt;0.024381&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; I was walking to of when I cam across a cat on the road&amp;lt;/s&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Pretty bad 👎, and see how the unconfident it is in its predictions! This doesn't perform well because we have only used 800 movie reviews to train our model, we'll need a lot more text to get decent results!&lt;/p&gt;
&lt;p&gt;Again, just for fun, lets see how it does on a movie review, lets look at an example from our validation set. We mask the word &lt;code&gt;might&lt;/code&gt; from the first sentence of the reivew, &lt;code&gt;... shows what might happen...&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# our validation split starts at index 800&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;mask&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what&amp;lt;mask&amp;gt; happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;b...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;,&lt;/td&gt;
      &lt;td&gt;0.044226&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what, happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;S...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;the&lt;/td&gt;
      &lt;td&gt;0.035027&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what the happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;0.028172&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what. happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;S...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;and&lt;/td&gt;
      &lt;td&gt;0.025764&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what and happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of ancient documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br ...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Ewww..&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;txts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# our validation split starts at index 800&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;&amp;lt;mask&amp;gt;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_mask_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;word&lt;/th&gt;
      &lt;th&gt;score&lt;/th&gt;
      &lt;th&gt;token&lt;/th&gt;
      &lt;th&gt;sequence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Input text&lt;/td&gt;
      &lt;td&gt;0.000000&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of&amp;lt;mask&amp;gt; documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br ...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;the&lt;/td&gt;
      &lt;td&gt;0.036510&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of the documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;,&lt;/td&gt;
      &lt;td&gt;0.035627&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of, documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;Sta...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;and&lt;/td&gt;
      &lt;td&gt;0.029176&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of and documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;.&lt;/td&gt;
      &lt;td&gt;0.029063&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; This very funny British comedy shows what might happen if a section of London, in this case Pimlico, were to declare itself independent from the rest of the UK and its laws, taxes &amp;amp; post-war restrictions. Merry mayhem is what would happen.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;The explosion of a wartime bomb leads to the discovery of. documents which show that Pimlico was ceded to the Duchy of Burgundy centuries ago, a small historical footnote long since forgotten. To the new Burgundians, however, this is an unexpected opportunity to live as they please, free from any interference from Whitehall.&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;Sta...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Yuck!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Notes-&amp;amp;-Hacky-Bits&quot;&gt;Notes &amp;amp; Hacky Bits&lt;a class=&quot;anchor-link&quot; href=&quot;#Notes-&amp;amp;-Hacky-Bits&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h4 id=&quot;Notes&quot;&gt;Notes&lt;a class=&quot;anchor-link&quot; href=&quot;#Notes&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The validation set will change slightly due to random masking. While the data in the validaion set remains constant, different tokens will be masked each time the validation dataloader is called due to &lt;code&gt;MLMTokensLabels&lt;/code&gt; calling a random probability each time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If a perfectly reproducable validation set is needed then you'll probably have to create a separate transform for it's masking and set it's &lt;code&gt;split_idx = 1&lt;/code&gt;.  &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I didn't have time to get &lt;code&gt;learn.predict&lt;/code&gt; working. One issue that needs to be fixed is that &lt;code&gt;MLMTokensLabels&lt;/code&gt; transform shouldn't be called on your masked input text as it will add more masks, which you don't want.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;FastHugsTokenizer&lt;/code&gt; will have to be modified to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;enable sequence lengths larger than the tokenizer default&lt;/li&gt;
&lt;li&gt;to use a non-pretrained tokenizer (e.g. one you trained yourself)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The HuggingFace &lt;code&gt;encode_plus&lt;/code&gt; or &lt;code&gt;batch_encode_plus&lt;/code&gt; functions are great and I would have used them, but don't play nice with fastai multiprocessiing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Hacks&quot;&gt;Hacks&lt;a class=&quot;anchor-link&quot; href=&quot;#Hacks&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I had to overwrite &lt;code&gt;__getitem__&lt;/code&gt; in the &lt;code&gt;Datasets&lt;/code&gt; class so that it wouldn't return a tuple as what it thinks is our &lt;code&gt;x&lt;/code&gt; is actually our &lt;code&gt;(x,y)&lt;/code&gt;. Wrapping this tuple in anoother tuple causes headaches down the line. Creating a custom &lt;code&gt;Datasets&lt;/code&gt; class and inheriting from it didn't work as &lt;code&gt;learn.predict&lt;/code&gt; calls on &lt;code&gt;Datasets&lt;/code&gt; and not the custom dataset class.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The function &lt;code&gt;get_mask_pred&lt;/code&gt; (used to view predictions of masked text) is mostly code from &lt;code&gt;FillMaskPipeline&lt;/code&gt; in HuggingFace's Transformers repo, full credit to them!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Give-me-a-shout-&amp;#128227;&quot;&gt;Give me a shout &amp;#128227;&lt;a class=&quot;anchor-link&quot; href=&quot;#Give-me-a-shout-&amp;#128227;&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Thats it for this, I hope you found it useful and learned a thing or two. If you have any questions or would like to get in touch you can find me on Twitter &lt;a href=&quot;www.twitter.com/mcgenergy&quot;&gt;@mcgenergy&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Morgan McGuire</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.ntentional.com/images/fasthugs.png" /><media:content medium="image" url="https://www.ntentional.com/images/fasthugs.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">FastHugs: Sequence Classification with Transformers and Fastai</title><link href="https://www.ntentional.com/nlp/training%20technique/classification/2020/04/17/fasthugs_seq_classification.html" rel="alternate" type="text/html" title="FastHugs: Sequence Classification with Transformers and Fastai" /><published>2020-04-17T00:00:00-05:00</published><updated>2020-04-17T00:00:00-05:00</updated><id>https://www.ntentional.com/nlp/training%20technique/classification/2020/04/17/fasthugs_seq_classification</id><content type="html" xml:base="https://www.ntentional.com/nlp/training%20technique/classification/2020/04/17/fasthugs_seq_classification.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-17-fasthugs_seq_classification.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;strong&gt;All FastHugs code can be found in my &lt;a href=&quot;https://github.com/morganmcg1/fasthugs&quot;&gt;FastHugs GitHub&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Things-You-Might-Like-(&amp;#10084;&amp;#65039;-?)&quot;&gt;Things You Might Like (&amp;#10084;&amp;#65039; ?)&lt;a class=&quot;anchor-link&quot; href=&quot;#Things-You-Might-Like-(&amp;#10084;&amp;#65039;-?)&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;FastHugsTokenizer:&lt;/strong&gt; A tokenizer wrapper than can be used with fastai-v2's tokenizer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FastHugsModel:&lt;/strong&gt; A model wrapper over the HF models, more or less the same to the wrapper's from HF fastai-v1 articles mentioned below&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Padding:&lt;/strong&gt; Padding settings for the padding token index and on whether the transformer prefers left or right padding&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Model Splitters:&lt;/strong&gt; Functions to split the classification head from the model backbone in line with fastai-v2's new definition of &lt;code&gt;Learner&lt;/code&gt; (in &lt;code&gt;splitters.py&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;Housekeeping&quot;&gt;Housekeeping&lt;a class=&quot;anchor-link&quot; href=&quot;#Housekeeping&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Pretrained-Transformers-only-for-now-&amp;#128528;&quot;&gt;Pretrained Transformers only for now &amp;#128528;&lt;a class=&quot;anchor-link&quot; href=&quot;#Pretrained-Transformers-only-for-now-&amp;#128528;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Initially, this notebook will only deal with finetuning HuggingFace's pretrained models. It covers BERT, DistilBERT, RoBERTa and ALBERT pretrained classification models only. These are the core transformer model architectures where HuggingFace have added a classification head. HuggingFace also has other versions of these model architectures such as the core model architecture and language model model architectures.&lt;/p&gt;
&lt;p&gt;If you'd like to try train a model from scratch HuggingFace just recently published an article on &lt;a href=&quot;https://huggingface.co/blog/how-to-train&quot;&gt;How to train a new language model from scratch using Transformers and Tokenizers&lt;/a&gt;. Its well worth reading to see how their &lt;code&gt;tokenizers&lt;/code&gt; library can be used, independent of their pretrained transformer models.&lt;/p&gt;
&lt;h3 id=&quot;Read-these-first-&amp;#128071;&quot;&gt;Read these first &amp;#128071;&lt;a class=&quot;anchor-link&quot; href=&quot;#Read-these-first-&amp;#128071;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This notebooks heavily borrows from &lt;a href=&quot;https://www.kaggle.com/melissarajaram/roberta-fastai-huggingface-transformers&quot;&gt;this notebook&lt;/a&gt; , which in turn is based off of this &lt;a href=&quot;https://www.kaggle.com/maroberti/fastai-with-transformers-bert-roberta&quot;&gt;tutorial&lt;/a&gt; and accompanying &lt;a href=&quot;https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2&quot;&gt;article&lt;/a&gt;. Huge thanks to  Melissa Rajaram and Maximilien Roberti for these great resources, if you're not familiar with the HuggingFace library please given them a read first as they are quite comprehensive.&lt;/p&gt;
&lt;h3 id=&quot;fastai-v2--&amp;#9996;&amp;#65039;2&amp;#65039;&amp;#8419;&quot;&gt;fastai-v2  &amp;#9996;&amp;#65039;2&amp;#65039;&amp;#8419;&lt;a class=&quot;anchor-link&quot; href=&quot;#fastai-v2--&amp;#9996;&amp;#65039;2&amp;#65039;&amp;#8419;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;&gt;This paper&lt;/a&gt; introduces the v2 version of the fastai library and you can follow and contribute to v2's progress &lt;a href=&quot;https://forums.fast.ai/&quot;&gt;on the forums&lt;/a&gt;. This notebook uses the small IMDB dataset and is based off the &lt;a href=&quot;http://dev.fast.ai/tutorial.ulmfit&quot;&gt;fastai-v2 ULMFiT tutorial&lt;/a&gt;. Huge thanks to Jeremy, Sylvain, Rachel and the fastai community for making this library what it is. I'm super excited about the additinal flexibility v2 brings. 🎉&lt;/p&gt;
&lt;h3 id=&quot;Dependencies-&amp;#128229;&quot;&gt;Dependencies &amp;#128229;&lt;a class=&quot;anchor-link&quot; href=&quot;#Dependencies-&amp;#128229;&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;If you haven't already, install HuggingFace's &lt;code&gt;transformers&lt;/code&gt; library with: &lt;code&gt;pip install transformers&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;untar_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;URLs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMDB_SAMPLE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;models&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;texts.csv&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;FastHugs-Tokenizer&quot;&gt;FastHugs Tokenizer&lt;a class=&quot;anchor-link&quot; href=&quot;#FastHugs-Tokenizer&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This tokenizer wrapper is initialised with the pretrained HF tokenizer, you can also specify the max_seq_len if you want longer/shorter sequences. Given text it returns tokens and adds separator tokens depending on the model type being used.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FastHugsTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot; &lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        transformer_tokenizer : takes the tokenizer that has been loaded from the tokenizer class&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        model_name : model type set by the user&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        max_seq_len : override default sequence length, typically 512 for bert-like models&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;        sentence_pair : whether a single sentence (sequence) or pair of sentences are used&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; 
                &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;WARNING: max_seq_len is larger than the model default transformer_tokenizer.max_len&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_sentences_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len_single_sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;do_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Limits the maximum sequence length and add the special tokens&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;CLS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SEP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sep_token&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Add prefix space, depending on model selected&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta&amp;#39;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add_prefix_space&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# order of &amp;#39;tokens&amp;#39;, &amp;#39;SEP&amp;#39; and &amp;#39;CLS&amp;#39;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;xlnet&amp;#39;&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SEP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CLS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CLS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SEP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__call__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;do_tokenize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;FastHugs-Model&quot;&gt;FastHugs Model&lt;a class=&quot;anchor-link&quot; href=&quot;#FastHugs-Model&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This &lt;code&gt;nn.module&lt;/code&gt; wraps the pretrained transformer model and initialises it with its config file.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;forward&lt;/code&gt; of this module is taken straight from Melissa's notebook above and its purpose is to create the attention mask and grab only the logits from the output of the model (as the HappyFace transformer models also output the loss).&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FastHugsModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;Inspired by https://www.kaggle.com/melissarajaram/roberta-fastai-huggingface-transformers/data&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FastHugsModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;  
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_num_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_class&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# load model&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_cls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_cls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;The-HuggingFace-bit&quot;&gt;The HuggingFace bit&lt;a class=&quot;anchor-link&quot; href=&quot;#The-HuggingFace-bit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Define-HuggingFace-Model-+-Config&quot;&gt;Define HuggingFace Model + Config&lt;a class=&quot;anchor-link&quot; href=&quot;#Define-HuggingFace-Model-+-Config&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AutoModelForSequenceClassification&lt;/code&gt; will define our model. When this is padded to the &lt;code&gt;FastHugsModel&lt;/code&gt; class below then model will be instantiated and the weights downloaded (if you are using a pretrained model)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;AutoConfig&lt;/code&gt; will define the model architecture and settings&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model_name&lt;/code&gt; is the model architecture (and optionally model weights) you'd like to use.&lt;ul&gt;
&lt;li&gt;Models tested: &lt;code&gt;bert-base-uncased&lt;/code&gt;, &lt;code&gt;roberta-base&lt;/code&gt;, &lt;code&gt;distilbert-base-cased&lt;/code&gt;, &lt;code&gt;albert-base-v2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;You can find all of HuggingFace's models at &lt;a href=&quot;https://huggingface.co/models&quot;&gt;https://huggingface.co/models&lt;/a&gt;, although not all of them are supported by &lt;code&gt;AutoModel&lt;/code&gt;,&lt;code&gt;AutoConfig&lt;/code&gt; and &lt;code&gt;AutoTokenizer&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta-base&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;model_class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoModelForSequenceClassification&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoConfig&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;HuggingFace-Config-changes&quot;&gt;HuggingFace Config changes&lt;a class=&quot;anchor-link&quot; href=&quot;#HuggingFace-Config-changes&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Some config settings can be changed even when using pretrained weights. For example in the &lt;code&gt;FastHugsModel&lt;/code&gt; class below &lt;code&gt;_num_labels&lt;/code&gt; is set when the model (pretrained or not) is instantiated, depending on how many classes you have in your dataloader.&lt;/p&gt;
&lt;p&gt;When creating a &lt;strong&gt;non-pretrained&lt;/strong&gt; model you can load a config with:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;code&gt;config_dict = AutoConfig.for_model(model_name)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Alternatively you could load a pretrained config and modify that. For example if your are &lt;strong&gt;not&lt;/strong&gt; using a pretrained model you can change the size of your input embeddings by changing &lt;code&gt;config_dict.max_position_embeddings = 1024&lt;/code&gt;. (This won't work when using pretrained models as the pre-trained weights need the default &lt;code&gt;max_position_embeddings&lt;/code&gt; size).&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;HuggingFace-Tokenizer-&amp;amp;-Vocab&quot;&gt;HuggingFace Tokenizer &amp;amp; Vocab&lt;a class=&quot;anchor-link&quot; href=&quot;#HuggingFace-Tokenizer-&amp;amp;-Vocab&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AutoTokenizer&lt;/code&gt; will load our tokenizer and enable us grab our vocab&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;fastai expects &lt;code&gt;vocab&lt;/code&gt; to be a list, however HuggingFace's &lt;code&gt;get_vocab&lt;/code&gt; returns a &lt;code&gt;token : index&lt;/code&gt; dict. We need to convert this dict to a list to be able to use it in fastai&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AutoTokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tokenizer_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])]&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;50265&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;The-Fastai-bit&quot;&gt;The Fastai bit&lt;a class=&quot;anchor-link&quot; href=&quot;#The-Fastai-bit&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Get-fastai-model-splitter-function&quot;&gt;Get fastai model splitter function&lt;a class=&quot;anchor-link&quot; href=&quot;#Get-fastai-model-splitter-function&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;In order to be able to fine-tune our classifier head we need to first split the HuggingFace model's classifier head from the body. These functions are dependent on the specific architecture and can be found in &lt;code&gt;splitter.py&lt;/code&gt; of this repo&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splitter_nm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;_cls_splitter&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_splitter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;splitters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splitter_nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;fasthugstok-and-our-tok_fn&quot;&gt;&lt;code&gt;fasthugstok&lt;/code&gt; and our &lt;code&gt;tok_fn&lt;/code&gt;&lt;a class=&quot;anchor-link&quot; href=&quot;#fasthugstok-and-our-tok_fn&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Lets incorporate the &lt;code&gt;tokenizer&lt;/code&gt; from HuggingFace into fastai-v2's framework by specifying a function called &lt;code&gt;fasthugstok&lt;/code&gt; that we can then pass on to &lt;code&gt;Tokenizer.from_df&lt;/code&gt;. (Note &lt;code&gt;.from_df&lt;/code&gt; is the only method I have tested)&lt;/p&gt;
&lt;h4 id=&quot;Max-Seqence-Length&quot;&gt;Max Seqence Length&lt;a class=&quot;anchor-link&quot; href=&quot;#Max-Seqence-Length&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;code&gt;max_seq_len&lt;/code&gt; is the longest sequece our tokenizer will output. We can also the max sequence length for the tokenizer by changing &lt;code&gt;max_seq_len&lt;/code&gt;. It uses the tokenizer's default, typically &lt;code&gt;512&lt;/code&gt;. &lt;code&gt;1024&lt;/code&gt; or even &lt;code&gt;2048&lt;/code&gt; can also be used depending on your GPU memory. Note when using pretrained models you won't be able to use a &lt;code&gt;max_seq_len&lt;/code&gt; larger than the default.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fasthugstok&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FastHugsTokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transformer_tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                      &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Set up fastai's &lt;code&gt;Tokenizer.from_df&lt;/code&gt;, we pass &lt;code&gt;rules=[]&lt;/code&gt; to override fastai's default text processing rules&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text_cols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_col_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;text&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fasthugstok&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rules&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Setup-Dataloaders&quot;&gt;Setup Dataloaders&lt;a class=&quot;anchor-link&quot; href=&quot;#Setup-Dataloaders&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Create-Dataset&quot;&gt;Create Dataset&lt;a class=&quot;anchor-link&quot; href=&quot;#Create-Dataset&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Lets add our custom tokenizer function (&lt;code&gt;tok_fn&lt;/code&gt;) and &lt;code&gt;transformer_vocab&lt;/code&gt; here&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ColSplitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_tfms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attrgetter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Numericalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;splits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_tfms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attrgetter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;label&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Categorize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dl_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SortedDL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Padding&quot;&gt;Padding&lt;a class=&quot;anchor-link&quot; href=&quot;#Padding&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;We need to make sure our padding is done correctly as some transformer models prefer padding on the left while others prefer it on the right. &lt;code&gt;tokenizer.padding_side&lt;/code&gt; will tell us which side is correct. e.g., BERT, Roberta prefers padding to the right, so we set &lt;code&gt;pad_first=False&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;transformer_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence_pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding_side&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;right&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ifnone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_input_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pad_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad_token_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Dataloaders&quot;&gt;Dataloaders&lt;a class=&quot;anchor-link&quot; href=&quot;#Dataloaders&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformer_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataloaders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;before_batch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trunc_at&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
      &lt;th&gt;category&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; ĠI Ġwas Ġfortunate Ġenough Ġto Ġmeet ĠGeorge ĠPal Ġ( and Ġstill Ġhave Ġmy ĠDS : TM OB Ġposter Ġaut ographed Ġby Ġhim ) Ġat Ġa Ġconvention Ġshortly Ġafter Ġthe Ġrelease , Ġand Ġasked Ġhim Ġwhy Ġhe Ġchose Ġto Ġdo Ġthe Ġfilm Ġ&quot; camp &quot;. ĠBefore Ġhe Ġcould Ġanswer , Ġtwo Ġstudio Ġfl acks Ġintercepted Ġand Ġlect ured Ġme Ġon&lt;/td&gt;
      &lt;td&gt;negative&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; ĠD ressed Ġto ĠKill Ġstarts Ġoff Ġwith ĠKate ĠMiller Ġ( Ang ie ĠDickinson ) Ġhaving Ġa Ġsexually Ġexplicit Ġnightmare , Ġlater Ġon Ġthat Ġday Ġshe Ġvisits Ġher Ġpsychiatrist ĠDr . ĠRobert ĠElliott Ġ( Michael ĠC aine ) Ġfor Ġa Ġsession Ġin Ġwhich Ġshe Ġadmits Ġto Ġbe Ġsexually Ġfrustrated Ġ&amp;amp; Ġun ful filled Ġin Ġher Ġcurrent Ġmarriage . ĠKate Ġthen&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; ĠSHALL OW ĠG RA VE Ġbegins Ġwith Ġeither Ġa Ġtribute Ġor Ġa Ġrip Ġoff Ġof Ġthe Ġshower Ġscene Ġin ĠPS Y CHO . Ġ( I 'm Ġleaning Ġtoward Ġrip Ġoff .) ĠAfter Ġthat Ġit Ġgets Ġworse Ġand Ġthen Ġsurprisingly Ġgets Ġbetter , Ġalmost Ġto Ġthe Ġpoint Ġof Ġbeing Ġoriginal . ĠBad Ġacting Ġand Ġamateur ish Ġdirecting Ġbog Ġdown Ġa&lt;/td&gt;
      &lt;td&gt;negative&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;(Alternatively)-Factory-dataloader&quot;&gt;(Alternatively) Factory dataloader&lt;a class=&quot;anchor-link&quot; href=&quot;#(Alternatively)-Factory-dataloader&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Here we set:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tok_tfm=tok_fn&lt;/code&gt; to use our HF tokenizer&lt;/li&gt;
&lt;li&gt;&lt;code&gt;text_vocab=transformer_vocab&lt;/code&gt; to load our pretrained vocab&lt;/li&gt;
&lt;li&gt;&lt;code&gt;before_batch=transformer_padding(transformer_tokenizer)&lt;/code&gt; to use our custom padding function &lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fct_dls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextDataLoaders&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok_tfm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fastai_tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer_vocab_ls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;before_batch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;label&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;is_valid&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fct_dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trunc_at&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;text&lt;/th&gt;
      &lt;th&gt;category&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; ĠI Ġwas Ġfortunate Ġenough Ġto Ġmeet ĠGeorge ĠPal Ġ( and Ġstill Ġhave Ġmy ĠDS : TM OB Ġposter Ġaut ographed Ġby Ġhim ) Ġat Ġa Ġconvention Ġshortly Ġafter Ġthe Ġrelease , Ġand Ġasked Ġhim Ġwhy Ġhe Ġchose Ġto Ġdo Ġthe Ġfilm Ġ&quot; camp &quot;. ĠBefore Ġhe Ġcould Ġanswer , Ġtwo Ġstudio Ġfl acks Ġintercepted Ġand Ġlect ured Ġme Ġon&lt;/td&gt;
      &lt;td&gt;negative&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; Ġ**** Don 't Ġread Ġthis Ġreview Ġif Ġyou Ġwant Ġthe Ġshocking Ġconclusion Ġof Ġ&quot; The ĠCr ater ĠLake ĠMonster &quot; Ġto Ġbe Ġa Ġtotal Ġsurprise **** &amp;lt; br Ġ/ &amp;gt;&amp;lt; br Ġ/&amp;gt; A Ġclay m ation Ġpl es ios aur Ġrises Ġfrom Ġthe Ġdepths Ġof ĠCr ater ĠLake Ġto Ġwre ak Ġhavoc Ġon Ġa Ġgroup Ġof Ġlocal Ġred ne&lt;/td&gt;
      &lt;td&gt;negative&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; ĠThis Ġis Ġthe Ġlast Ġof Ġfour Ġsw ash buck lers Ġfrom ĠFrance ĠI 've Ġscheduled Ġfor Ġviewing Ġduring Ġthis ĠChristmas Ġseason : Ġthe Ġothers Ġ( in Ġorder Ġof Ġviewing ) Ġwere Ġthe Ġun inspired ĠTHE ĠBLACK ĠT UL IP Ġ( 1964 ; Ġfrom Ġthe Ġsame Ġdirector Ġas Ġthis Ġone Ġbut Ġnot Ġnearly Ġas Ġgood ), Ġthe Ġsurprisingly Ġeffective ĠL&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Create-our-learner&quot;&gt;Create our learner&lt;a class=&quot;anchor-link&quot; href=&quot;#Create-our-learner&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decouple_wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LabelSmoothingCrossEntropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fasthugs_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FastHugsModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transformer_cls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fasthugs_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;splitter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_splitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Stage-1-training&quot;&gt;Stage 1 training&lt;a class=&quot;anchor-link&quot; href=&quot;#Stage-1-training&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Lets freeze the model backbone and only train the classifier head. &lt;code&gt;freeze_to(1)&lt;/code&gt; means that only the classifier head is trainable&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freeze_to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Lets find a learning rate to train our classifier head&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;suggestions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SuggestedLRs(lr_min=9.999999747378752e-07, lr_steep=0.10000000149011612)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recorder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;9.999e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.65&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.65&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;&amp;lt;matplotlib.collections.LineCollection at 0x7f7582802450&amp;gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxcVZ338c+vqnpfk+5OJ+nsGyQECEnYRDDIItuA4jKgjqJoRB0ddWYe9XFBfR7UcXlGcWNQAcdRGASVgAxRkcgigSSEhKwQkpB00lu603t3dXXVef6o6tBJujvdnb59a/m+X696pe5S9/5Oqqt+dc6551xzziEiIpkr4HcAIiLiLyUCEZEMp0QgIpLhlAhERDKcEoGISIZTIhARyXAhvwMYqfLycjdr1iy/wxARSSkbNmw45JyrGGhbyiWCWbNmsX79er/DEBFJKWb22mDb1DQkIpLhlAhERDKcEoGISIZTIhARyXBKBCIiGU6JQEQkwykRiIikgD9tq2NXfbsnx1YiEBFJcrGY42O/2sADG6o9Ob4SgYhIkmvpihCJOiYV5XhyfCUCEZEkV98WBqBCiUBEJDM1KBGIiGS2+rZuADUNiYhkKtUIREQyXENbmLysIIU53kwYrUQgIpLk6tvCVBTlYGaeHF+JQEQkyTW0hT3rHwAlAhGRpFff1u1Z/wB4mAjM7C4zqzezLUPss8LMXjSzrWb2V69iERFJZalcI7gHuGKwjWZWCvwYuNY5dxrwTg9jERFJSd2RKK3dvalZI3DOPQk0DbHLu4HfOuf2Jfav9yoWEZFU5fWlo+BvH8ECYIKZrTGzDWb2Ph9jERFJSg3t8UQwqSjXs3N4c1Hq8M+9DLgEyAOeNbO1zrmXj93RzFYCKwFmzJgxrkGKiPipvjW9awTVwGPOuQ7n3CHgSeDMgXZ0zt3pnFvunFteUVExrkGKiPjp9RpBeiaCh4ALzSxkZvnAucB2H+MREUk6DW1hzGBiQbZn5/CsacjM7gVWAOVmVg3cCmQBOOfucM5tN7PHgM1ADPiZc27QS01FRDJRQ1s3ZQU5hILe/W73LBE4524cxj7fBr7tVQwiIqmuITG9hJc0slhEJInVezyYDJQIRESSmmoEIiIZLBZzHGpXIhARyVjNHt+0vo8SgYhIkhqP6SVAiUBEJGm9fq9i76aXACUCEZGkpRqBiEiGq2/zfnoJUCIQEUlaDW1h8rODFHh00/o+SgQiIklqPMYQgBKBiEjSqm/r9rxZCJQIRESSlmoEIiIZLj7PkLeXjoISgYhIUuqORGnz+Kb1fZQIRESS0HiNIQAlAhGRpFSvRCAiktkaxmkwGSgRiIgkpYbEPEOqEYiIZIjdDe00toePLDe0hQkYlBUoEYiIZISb7l7HVbc/xdaDLQA0tIcpK8whGDDPz61EICLis2jMcaC5i7rWMO+641me2FlPfWuYikLvawOgRCAi4rtD7WGiMccn3jyPWeUFfOgX63l+bxOTipUIREQyQm1LvGP49KoS7v/I+Vw0vzw+mGycagTezm0qIiInVNsaTwSTS3IpyAnx0/ct586ndnP+nLJxOb8SgYiIz+r6EkFxfF6hUDDAx1bMG7fzq2lIRMRnda3dBANG2Tg1BR1LiUBExGe1LWEmFY3PpaIDUSIQEfFZXWs3lcXeTzc9GCUCERGf1bZ2H+kf8IMSgYiIz+pauplckoaJwMzuMrN6M9tygv3ONrOomb3Dq1hERJJVR7iXtnBv2jYN3QNcMdQOZhYE/g1Y7WEcIiJJ6/UxBP5cMQQeJgLn3JNA0wl2+wTwIFDvVRwiIsmsLjGqOF1rBEMysyrgbcAdfsUgIuK32mMGk/nBz87i7wGfdc5FT7Sjma00s/Vmtr6hoWEcQhMRGR/9p5fwi59TTCwH7jMzgHLgKjPrdc79/tgdnXN3AncCLF++3I1rlCIiHqpr6aYoN0R+tn9fx76d2Tk3u++5md0DPDJQEhARSWd+jyEADxOBmd0LrADKzawauBXIAnDOqV9ARASobQ372iwEHiYC59yNI9j3Jq/iEBFJZnUt3cyfVO5rDBpZLCLik2jM0dAe9r1pSIlARMQnfbeorPS5aUiJQETEJ323qFSNQEQkQyXDYDJQIhAR8U3fLSorfZxnCJQIRER8U9vSTShglBcoEYiIZKTa1m4mFeUQ8OkWlX2UCEREfFLX2u37FUOgRCAi4pvaFv+nlwAlAhER39S1hn29D0EfJQIRER+0h3tpD/f6Ps8QKBGIiPgiWQaTgRKBiIgvjowhUCIQEclMR2oEahoSEclMyTK9BCgRiIj4oq61m+LcEHnZQb9DUSIQEfFDbUt3UjQLgRKBiIgv6lq7k6KjGJQIRER8UX24i6rSPL/DAJQIRETGXVt3hMaOHmaVF/gdCqBEICIy7l5r7ARgVlm+z5HEKRGIiIyzvkQwY6JqBCIiGWlvYwcAM1UjEBHJTK81dlBRlENBTsjvUAAlAhGRcbe3sTNp+gdAiUBEZNzta+xMmv4BUCIQERlXXT1Ralu7VSMQEclU+5riVwzNTJIxBKBEICIyrvquGFKNQEQkQ+1LjCGYmQl9BGZ2l5nVm9mWQba/x8w2Jx5/M7MzvYpFRCRZ7G3soDQ/i5L8LL9DOcLLGsE9wBVDbN8DvMk5dwbwf4A7PYxFRCQpvNbYycyy5KkNgIeJwDn3JNA0xPa/OecOJxbXAtO8ikVEJFnsbexIqv4BGGYiMLO5ZpaTeL7CzD5pZqVjGMfNwP8Mcf6VZrbezNY3NDSM4WlFRMZPT2+Mg81dKVsjeBCImtk84OfAbODXYxGAmV1MPBF8drB9nHN3OueWO+eWV1RUjMVpRUTGXfXhTmIOZk5MwRoBEHPO9QJvA77nnPs0MOVkT25mZwA/A65zzjWe7PFERJLZkemny1MzEUTM7Ebg/cAjiXUn1eVtZjOA3wL/4Jx7+WSOJSKSCl6fdTS5moaGO/XdB4BbgNucc3vMbDbwX0O9wMzuBVYA5WZWDdxKInk45+4AvgyUAT82M4Be59zy0RRCRCQVvNbYSWFOiLKCbL9DOcqwEoFzbhvwSQAzmwAUOee+eYLX3HiC7R8CPjTMOEVEUt7exg5mTMwn8eM3aQz3qqE1ZlZsZhOBTcDdZvb/vA1NRCS97GvsTLr+ARh+H0GJc64VuB642zm3DLjUu7BERNJLbzTG/sPJN5gMhp8IQmY2BXgXr3cWi4jIMNW0dBOJuqQbTAbDTwRfA1YDrzrn1pnZHOAV78ISEUkvyXrFEAy/s/g3wG/6Le8G3u5VUCIi6aZvDEGy3LC+v+F2Fk8zs98lZhOtM7MHzUxzA4mIDNNrjR3khAJUFuX6Hcpxhts0dDewCpgKVAEPJ9aJiMgw7G3sZGZZPoFAcl06CsNPBBXOubudc72Jxz2AJv0RERmG5s4e1r7ayOKpJX6HMqDhJoJDZvZeMwsmHu8FNDeQiMgw3PX0HtrCvax80xy/QxnQcBPBB4lfOloL1ADvID7thIiIDKG5s4e7n9nLVadP5tTJxX6HM6BhJQLn3D7n3LXOuQrn3CTn3FuJDy4TEZEh9NUGPnnJfL9DGdTJ3KHsM2MWhYhIGkqF2gCcXCJIvq5vEZEkkgq1ATi5RODGLAoRkTTTVxu4cnFy1wbgBCOLzayNgb/wDcjzJCIZ0ooVKwBYs2aNr3GIyNDuembviGoDfn62h0wEzrmi8QpERCSdPLLpIBfOL2fhlOSuDcDJNQ2JiMgA6lu72X2ogwvnl/sdyrAoEYiIjLHn9jQBcM7sMp8jGR4lAhGRMfbcnkYKsoMsnpr8zUKgRCAiMuae39PEslkTCQVT4ys2NaIUEUkRTR09vFzXzrmzJ/odyrApEYiIjKHn98Tn4zxvjhKBiEhGWru7idysAKdXlfodyrApEYiIjKHn9jSxdMYEskOp8/WaOpGKiCS5ls4IO2pbOTdFLhvto0QgIjJG1u1twjk4N4X6B0CJQERkzDy3p5HsYIAl01OnfwCUCERExsxze5pYMr2U3Kyg36GMiBKBiMgYaOuOsOVAS8o1C4ESgYjImNjw2mFijpTrKAYPE4GZ3WVm9Wa2ZZDtZma3m9kuM9tsZku9ikVExGvP7WkiFDCWzkyt/gHwtkZwD3DFENuvBOYnHiuBn3gYi4iIpzbuO8xpU4vJzx7yNi9JybNE4Jx7EmgaYpfrgP90cWuBUjOb4lU8IiJecc6xvaaNRVNL/A5lVPzsI6gC9vdbrk6sO46ZrTSz9Wa2vqGhYVyCExEZrtrWblq6Iiyckpo3dfQzEdgA6wa6PzLOuTudc8udc8srKio8DktEZGS217QCpMRtKQfiZyKoBqb3W54GHPQpFhGRUdte0wbAKZNVIxipVcD7ElcPnQe0OOdqfIxHRGRUtte0Mm1CHsW5WX6HMiqedW+b2b3ACqDczKqBW4EsAOfcHcCjwFXALqAT+IBXsYiIeGl7TWvKNguBh4nAOXfjCbY74ONenV9EZDx0R6LsOdTB1aen7kWPGlksInISXq5rI+ZSt6MYlAhERE5K3xVDpyoRiIhkpu01beRlBZk5Md/vUEZNiUBE5CRsr2nllMlFBAIDDY1KDUoEIiKj5JxjR21bSvcPgBKBiMio1bTEp5ZYlKJTS/RRIhARGaV06CgGJQIRkVHbUZvaU0v0USIQERmlbSk+tUQfJQIRkVHakeJTS/RRIhARGYW+qSWUCEREMtTO2sTUEinePwBKBCIio7KjNrVvRtOfEoGIyChsr2kjPzvIjBSeWqKPEoGIyCisf62JxVUlKT21RB8lAhGREWrpirD1YCvnzynzO5QxoUQgIjJCz+9pwjk4f64SgYhIRlq7u5HsUIAl00v9DmVMKBGIiIzQs682smzGBHKzgn6HMiaUCERERqC5s4ftta2clyb9A6BEICIyIs+lWf8AKBGIiIzI2t2N5GYFOHN6id+hjJmMTQSv1LXxT/dtpDsS9TsUEUkhz77ayLKZE8gJpUf/AGRwIvjFs3t56MWDPL693u9QRCRFHO7oYUdtW9qMH+iTkYkgFnOs3loHwKMv1fgcjYikiuf2NAKkVUcxQMjvAPywcf9hGtrCTC3J5fEddXT29JKfnZH/FSKS8Mtn93LHX3dTNSGP+ZMKmT+pkOWzJrK46vW+gLW7m8jLCnLGtPQYP9AnI2sEj22pJTsY4CvXnkZ3JMYTOxr8DklEfPTMrkPcumorZYXZxGKOhzcd5CsPb+Pvfvg0P16zC+ccEO8fWD5rAtmh9PrqzLifwc45HttaywXzyrhkYSXlhdk8+lINV58xxe/QRMQHB5u7+MS9G5lbUci9Hz6PgpwQzjnq28L83z9s51uP7WTbwVY+d+Wp7Kxr49olU/0OecxlXCLYVtPK/qYu/vHieQQDxhWLJ/PghgNqHhLJQOHeKB/91Qv09Ma44x+WUZAT/w4wMyqLc7n9hiUsmlLMt1bv4Jldh4D06x+ADGwaWr2lloDBpQsrAbjq9Cl0RaJqHhLJQF99eBub9jfznXeeydyKwuO2mxkfXTGXu95/Nr0xR2FOiDOmpc/4gT6eJgIzu8LMdprZLjP73ADbZ5jZE2a20cw2m9lVXsYD8NjWWs6ZPZGywhwAzp1ddqR5SEQyx8ObDvLr5/Zxy5vmcsXiyUPue/Gpk3jsUxdx38rzyAqm3+9nz0pkZkHgR8CVwCLgRjNbdMxuXwTud86dBdwA/NireABebWjn5bp2rjjt9Te9r3noLzvq6erR4DKRTNAdifKNR7ezuKqYf7l8wbBeU1Wad9QVROnEy9R2DrDLObfbOdcD3Adcd8w+Dui74WcJcNDDeFi9tRaAy087OvsfaR7aqcFlIpngrmf2cLClmy9ctYhQGv7CHykv/weqgP39lqsT6/r7CvBeM6sGHgU+MdCBzGylma03s/UNDaNvy1+9pZYzp5cytTTvqPV9zUN/2KzmIZF019ge5sdPvMqlCyel1cRxJ8PLy2QGupGnO2b5RuAe59x3zex84Jdmttg5FzvqRc7dCdwJsHz58mOPMSwHmrvYVN3C56489bht/a8eamwPH+k/EJHxtXZ3IxPys5k3qZDgMO8FXNPSxbOvNvLsq43sqG1jQkE2U4pzmVySy5yKAq4+fcpRv/pvf/wVuiLRAb8LMpWXiaAamN5veRrHN/3cDFwB4Jx71sxygXJgzNtonk8MDX/LaQN3Cr3v/Fn897r9fHnVVn707qVjfXoROYE/bq1l5S83AFCYE+LM6SUsnTGBJdNLWTK99MgPtEg0xrq9Tfx5Wz1P7Kxnz6EOAErysji9qoTmzh521LTS0B7GOfj503v4zjvPZEFlEbsb2vnVc/u44ezpzJtU5FtZk42XiWAdMN/MZgMHiHcGv/uYffYBlwD3mNlCIBfw5DrOt501jXNnlx3XLNRnQWURn7p0Ad9evZMrFx/kmjPSb9CISLLqCPfylVVbOXVyESsvmsML+w6zcV8zP17zKtFYvBFgZlk+c8oLeGFfMy1dEbJDAd4wt4z3nDuD8+eWsXByMYF+tYhINMYft9bxpYe2cM3tT/Opy+azcV8zOaEAn7p0eB3EmcKzROCc6zWzfwRWA0HgLufcVjP7GrDeObcK+Gfgp2b2aeLNRje5vrHcHhgsCfT5yEVzWL21li/9fgvnzi6jokhNRCLj4d//9DI1rd384N1LWTZzAtcvnQZAZ08vWw60snHfYV7c38yu+nYuW1TJZYsquXB++ZCDQLOCAa4+YwrnzpnIlx/awrce2wnAv1y+QJ/tY3g6lNY59yjxTuD+677c7/k24AIvYxiJUDDAd995Jlff/jRf/P1L3PHeZZgNr51SREZn68EW7v7bXm48ZwbLZk44alt+dohzZk/knNkTR3388sIcfvyeZTyy+SBrdjZw8xvnnGzIaUfXTR1jfmURn7l8Aau31rFqk6dXs4pkvGjM8b9/t4UJ+Vl89i3edt5ec8ZUvvPOM8nLTp8byowVTa4zgA9fGG8i+uLvtpCXFTxu3IGIjNyWAy186aEt5IQCnD1rImfPmsjLdW1s2t/M929YQkl+lt8hZiwlggEEA8YPbjyLW/5rAyt/uYH3njeDL169iNys+C+JutZuHnyhmoa2MO9cNp1FU4tPcESRzHb/uv188aH4L/9JRbn86IldJPqAeeO8cq49Uxdn+EmJYBDTJuTz4EffwHdW7+SnT+3hud1NfOjC2azeWseanfXEHGQHA9z9zF7OmTWR979hFpefVpmW85CIjFZ3JMpXVm3lvnX7uWBeGbffcBZlhTm0h3vZuO8wLx1o4W1nVakvzmdKBEPICQX5wtWLuHB+BZ+5fxOfffAlJhfn8tEVc3nHsulMzM/m/vX7+c+1e/n4r1/g1MlFPPDRN1CYo/9WyWy90RiPba3lh3/ZxY7aNj62Yi7/fPkpRwaJFeaEuHB+BRfOr/A5UgElgmG5aEEFf/r0Rew+1MGS6aVHjXj88EVz+OAbZ/PI5oN8+r9f5HMPbuYHN5416l84kWiMzdXNrN3dRE9vjKmluUwpyWNqaS6zy4+fJldkPPVGYxxq76GtO0Jrdy/t4V6yAkZxXhbFuVnkZgf4w+Yafv70HqoPdzG7vICfvW85ly6q9Dt0GYISwTBNKMhmWUH2gNuCAeO6JVUcaO7iW4/tZNnMCXzggtknPGZPb4zXGjvYVd/Orvp2Xth3mOf3NNGRmAXVDPqPqjilsohw4RRy2jUnkoy/cG+Ud/zkWV460HLCfZfPnMCXrlnEpQsrhz1VhPhHiWAM3XLRXF547TC3/WE7Z0wrPe6aaOcc22pa+dO2Ov68vY7tNW1HRk0CzKko4Pql03jD3DLOnVNGYU6IutZualq6ebWhndsff4Wa095DUe0LtId71QQl4+oHj+/ipQMt/PNlC5hZXkBRboji3BC9UUdrdy8tXRHauiMD/u1LcjMPB/J6Yvny5W79+vV+hzGols4I1/zwKXqjjoc+fgGH2nvYVN3Mpv3NPPXKIQ40d2EGS2dM4Pw5ZcybVMjcikLmVBQcuU3eYNq6I7zhlm/SVnkWU0rz+Oq1p+nSVhkXWw60cN2PnuGtS6r47rvO9DuctLRixQoA1qxZ48nxzWyDc275QNv0k3KMleRn8ZP3LOP6n/yNc77++Ovr87I4e9YEPnnJPN58auWohrgX5WZRtvdxCg5to+TSj7Lylxu4dOEkbv2705g+MX8siyHD1B2J8vQrh8jJCjClJJfJJXlH1dScc/REY7R0RWjujHC4o4fmrgidPb20h6N0hnvpCMd/TTcn9ukI95KbFSQ3K0h+dpCCnCAledmU5mcxIT+LkrwsCnJCFOSEKMwJUZqXRUVRzlH9Uj29MZ7f08TjO+qIxhwfedNcqk4wxcpgItEY/+uBzUwsyOZL1yw86f8zST5KBB5YXFXCj969lLW7GzljWglnTitlZln+mF0il9tew8OfeCN3P7OH7/35FS7797/yyUvm8/7zZ52wViFjY8+hDn619jUeeKGa5s7IUdvyEyNXe6PxJHAiZvEfCqV58S/5/OwQXZEojR09dEeitId7ae7sIRIdvPaenx1kVlkBs8sL6I3FeGZXI+3hXrJD8cuZ71u3nw9cMIuPrZhHSd7IBm7d+eRuttW0csd7l1GaP3A/maQ2fWt4pG9iLK9kBQOsvGgu15wxla8+vJVvPbaT76zeyYLKIs6aMYGzZpRy8SmTNLnWCLWHe1m3p4m61m7auntp647QFu6lMxylKxKlsydKY0eYjfuaCQWMtyyezA1nTycnFKSmpYvalm7q28IYkBUKkBUwskOB+Bd9fjYT8uO/7AtzQuTnBCnMCZEbCh41a+ZAnHN0RaIc7ozQ0hmhoyd+xU5HuJfG9h72Nnaw51AHWw+2EIk6rl0ylTefMok3zCvjcGeE7/5xJ3c+uZv71+3nH86fxfKZEzhjWgml+dlH+q6e2FHPmp0NhHtjLJleytKZpVQU5vL9P7/C1adPOeF9fSV1qY8gxQzWjvj8niae2XWIjfubeXHfYVq7ewkGjDctqOD6pVVcurDyyMhoeZ1zjq0HW/nryw389eUGXnjtML2xoz8ThTkh8rPjzTR52SEKc4JcNL+Cvz9nOpOKcn2KfOS2HGjh3x7bwVOvHDqybmZZPuFIjNrWbgDOmFZCQXaIzdXNR65eK83P4k+ffpN+VHhMfQRy0vrP0BiLOV6ub+OhFw/yuxcO8Jcd9RTlhrjxnBnc/MbZVBYn95dXdyRKa1fkuHbvPg1tYXbVtx/5FbznUAetXRGCASMYMAJmTMjPYsbEfKZPzGfGxHwqi3OZkJ9NUW6IQMB4taGdVS8eZNWmg0dubHLa1GI+dOEcLpxfzqzEVTGF2aET/lpPFYurSvjlzefS0hVh64EWNlW3sLm6GTNYccokVpxScSSxRWOOl+va2LivmYVTipQE0pxqBClmpL8aojHH2t2N3Pv8Ph59qYZQIMDbl1Vx8xvnEI05dtS2sq2mleqmLq46fQpXLp7syxdfe7iXv+yo57EtNTyxo4GuSJSSvCxOqSzilMlF5IQC7KhtY0dtK4fae468LjsUYFZZPqX52cRijqhzxGKOxo4eDjZ3ccyPe4IBoyg3RHNnBDM4b3YZ1y6ZymWLKinXLUrFR6oRiGeCAeOCeeVcMK+cfY2d/MeTr/KbDdXc+/z+I/tkBY2SvGz+8FINp06O36ntLadVDvhrvDcab0boa0NvD/fS3t1LVyRKKGCEggGyggFyswKUFeRQURR/FOeGjjteU0cPf95exx+31vLkK4fo6Y1RXpjD9UurmDepkFfq29lZ28bvNh4gEo2xoLKIi0+ZxMIpxcyvLGR2eQFTSvIGHbAUicY42NzFa42dNLSFOdzZw+HOHpo7I8ypKOSaM6Ykfe1IZDwoEWSQGWX53Pa20/mnS+azatNBygqzWTilmLkVhQTMeGTzQb7/51e45b82sKCykMkleURjMaIxR09vjNqWbmpbu4/7lT0c2aEAFYU5lBdmU1GUQ1t3L+v2NhFzUFWax3vOncGVi6ewbOaE477YnXPEHCMeoZoVDDCzrICZZQUjD1gkgygRZKBJxbl86MLj79J03ZIqrj59Cg+9eJD/Xreflq4IoYARNCMvO8h5c8uoKs2jqjSPySW5FOfFr34pyAmRlxWkNxajN+rojcavcDnUHuZQe5iGtjD1bWEOtYVpaA9zoLkbAz62Yh5XLJ7MaVOLh7y01swIpkczvUhSUiKQo4SCAd6+bBpvXzbtpI91CkVjEJGIeE2T54uIZDglAhGRDKdEICKS4ZQIREQynDqLU4xXg01ExF9+frZVIxARyXBKBCIiGU6JQEQkwykRiIhkOCUCEZEM52kiMLMrzGynme0ys88Nss+7zGybmW01s197GY+IiBzPs8tHzSwI/Ai4DKgG1pnZKufctn77zAc+D1zgnDtsZpO8ikdERAbmZY3gHGCXc263c64HuA+47ph9Pgz8yDl3GMA5V+9hPCIiMgAvE0EVsL/fcnViXX8LgAVm9oyZrTWzKzyMR0REBuDlyOKBZpA/9pYmIWA+sAKYBjxlZoudc81HHchsJbAysdhuZrVAS2K5pN/zY5f7nvf9Ww4cYnSOPc9I9hlo/XDiHuy5l+UYavtQMQ+1PN5lGGqfsXgv+q/z471Ipb+nofYZy/cilcvQ/7mX5Zg56BbnnCcP4Hxgdb/lzwOfP2afO4Cb+i0/Dpw9jGPfOdDzwbb1+3f9SZTnztHuM9D64cQ9RHk8K8dQ24eKeajl8S6D1+/FMevG/b1Ipb+n8XovUrkM41mOwR5eNg2tA+ab2WwzywZuAFYds8/vgYsBzKyceFPR7mEc++FBng+27dh9RmM4xxhsn4HWDyfuoZ6P1omOMdT2oWIeanm8yzDUPmPxXoxFGYZznHT4expqn2R5L/wuw3BjOJFRH8MSmcQTZnYV8D0gCNzlnLvNzL5GPOutsvj9Cb8LXAFEgducc/d5GM9659xyr44/XtKhHOlQBkiPcqgMycOvcng6+6hz7lHg0WPWfbnfcwd8JvEYD3eO03m8lg7lSIcyQHqUQ2VIHr6Uw9MagYiIJD9NMSEikkCSM5YAAAYTSURBVOGUCEREMpwSgYhIhlMiSDCzC83sDjP7mZn9ze94RsPMAmZ2m5n9wMze73c8o2VmK8zsqcT7scLveEbLzArMbIOZXeN3LKNlZgsT78MDZvZRv+MZDTN7q5n91MweMrPL/Y5ntMxsjpn93MweGOtjp0UiMLO7zKzezLYcs/6Es5/2cc495Zy7BXgE+IWX8Q5kLMpAfC6nKiBCfEqPcTdG5XBAO5CLD+UYozIAfBa435soT2yMPhfbE5+LdwHjflnjGJXh9865DwM3AX/vYbiDGqNy7HbO3exJgKMdiZZMD+AiYCmwpd+6IPAqMAfIBjYBi4DTiX/Z939M6ve6+4HiVCwD8DngI4nXPpCq7wUQSLyuEvhVipbhUuKDKG8CrknV9yLxmmuBvwHvTtUyJF73XWBpKr8XideN+Wfb03EE48U596SZzTpm9ZHZTwHM7D7gOufcN4ABq+pmNgNocc61ehjugMaiDGZWDfQkFqPeRTu4sXovEg4DOV7EOZQxei8uBgqIf7C7zOxR51zM08CPMVbvhXNuFbDKzP4AjOs9Q8bovTDgm8D/OOde8DbigY3x52LMpUUiGMRAs5+ee4LX3Azc7VlEIzfSMvwW+IGZXQg86WVgIzSicpjZ9cBbgFLgh96GNmwjKoNz7gsAZnYTcGi8k8AQRvperACuJ56QHx1sv3E20s/FJ4jX0ErMbJ5z7g4vgxuBkb4XZcBtwFlm9vlEwhgT6ZwIhjP76dEbnbvVo1hGa0RlcM51Ek9myWak5fgt8aSWTEb89wTgnLtn7EM5KSN9L9YAa7wKZpRGWobbgdu9C2fURlqORuAWLwJJi87iQVQD0/stTwMO+hTLaKVDGSA9ypEOZYD0KEc6lAGSqBzpnAiGM/tpskuHMkB6lCMdygDpUY50KAMkUzn86EH3oEf+XqCG1y+bvDmx/irgZeI981/wO850L0O6lCMdypAu5UiHMqRCOTTpnIhIhkvnpiERERkGJQIRkQynRCAikuGUCEREMpwSgYhIhlMiEBHJcEoEkhbMrH2cz/czM1s0RseKmtmLZrbFzB42s9IT7F9qZh8bi3OLgG5eL2nCzNqdc4VjeLyQc653rI53gnMdid3MfgG87Jy7bYj9ZwGPOOcWj0d8kv5UI5C0ZWYVZvagma1LPC5IrD/HzP5mZhsT/56SWH+Tmf3GzB4G/mjxO6WtsfjduXaY2a8SUxqTWL888bzd4neG22Rma82sMrF+bmJ5nZl9bZi1lmeJz0qJmRWa2eNm9oKZvWRm1yX2+SYwN1GL+HZi339NnGezmX11DP8bJQMoEUg6+z7w7865s4G3Az9LrN8BXOScOwv4MvD1fq85H3i/c+7NieWzgE8Rv6/AHOCCAc5TAKx1zp1JfPrvD/c7//cT5z/hZGJmFgQu4fX5ZrqBtznnlgIXA99NJKLPAa8655Y45/7V4rdfnE98fvslwDIzu+hE5xPpk87TUItcCixK/IgHKDazIqAE+IWZzSc+7W9Wv9f8yTnX1G/5eedcNYCZvQjMAp4+5jw9xO8iBbABuCzx/HzgrYnnvwa+M0icef2OvQH4U2K9AV9PfKnHiNcUKgd4/eWJx8bEciHxxJBM96SQJKZEIOksAJzvnOvqv9LMfgA84Zx7W6K9fU2/zR3HHCPc73mUgT8zEfd6Z9tg+wylyzm3xMxKiCeUjxOfP/89QAWwzDkXMbO9xO/jfCwDvuGc+48RnlcEUNOQpLc/Av/Yt2BmSxJPS4ADiec3eXj+tcSbpCA+xfCQnHMtwCeBfzGzLOJx1ieSwMXAzMSubUBRv5euBj5oZn0dzlVmNmmMyiAZQIlA0kW+mVX3e3yG+Jfq8kQH6jZev7vTt4BvmNkzxG8g7pVPAZ8xs+eBKUDLiV7gnNtI/CbmNwC/Ih7/euK1gx2JfRqBZxKXm37bOfdH4k1Pz5rZS8ADHJ0oRIaky0dFPGJm+cSbfZyZ3QDc6Jy77kSvExlv6iMQ8c4y4IeJK32agQ/6HI/IgFQjEBHJcOojEBHJcEoEIiIZTolARCTDKRGIiGQ4JQIRkQynRCAikuH+P6sW/AbMbyZXAAAAAElFTkSuQmCC
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: left;&quot;&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.692172&lt;/td&gt;
      &lt;td&gt;0.653464&lt;/td&gt;
      &lt;td&gt;0.550000&lt;/td&gt;
      &lt;td&gt;00:07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.573368&lt;/td&gt;
      &lt;td&gt;0.591558&lt;/td&gt;
      &lt;td&gt;0.635000&lt;/td&gt;
      &lt;td&gt;00:07&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.522324&lt;/td&gt;
      &lt;td&gt;0.533852&lt;/td&gt;
      &lt;td&gt;0.810000&lt;/td&gt;
      &lt;td&gt;00:07&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta-fasthugs-stg1-1e-3&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recorder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Stage-2-training&quot;&gt;Stage 2 training&lt;a class=&quot;anchor-link&quot; href=&quot;#Stage-2-training&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;And now lets train the full model with differential learning rates&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unfreeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;suggestions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;SuggestedLRs(lr_min=6.309573450380412e-08, lr_steep=0.03981071710586548)&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recorder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_lr_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;6.30e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vlines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.039&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;&amp;lt;matplotlib.collections.LineCollection at 0x7f7582464490&amp;gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: left;&quot;&gt;
      &lt;th&gt;epoch&lt;/th&gt;
      &lt;th&gt;train_loss&lt;/th&gt;
      &lt;th&gt;valid_loss&lt;/th&gt;
      &lt;th&gt;accuracy&lt;/th&gt;
      &lt;th&gt;time&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.425518&lt;/td&gt;
      &lt;td&gt;0.354511&lt;/td&gt;
      &lt;td&gt;0.910000&lt;/td&gt;
      &lt;td&gt;00:31&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.278425&lt;/td&gt;
      &lt;td&gt;0.372734&lt;/td&gt;
      &lt;td&gt;0.910000&lt;/td&gt;
      &lt;td&gt;00:32&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.272590&lt;/td&gt;
      &lt;td&gt;0.366681&lt;/td&gt;
      &lt;td&gt;0.925000&lt;/td&gt;
      &lt;td&gt;00:31&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;roberta-fasthugs-stg2-3e-5&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recorder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_png output_subarea &quot;&gt;
&lt;img src=&quot;data:image/png;base64,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
&quot; /&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Lets-Look-at-the-model's-predictions&quot;&gt;Lets Look at the model's predictions&lt;a class=&quot;anchor-link&quot; href=&quot;#Lets-Look-at-the-model's-predictions&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;This was a really good movie, i loved it&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;



&lt;div class=&quot;output_text output_subarea output_execute_result&quot;&gt;
&lt;pre&gt;(&amp;#39;positive&amp;#39;, tensor(1), tensor([0.1498, 0.8502]))&lt;/pre&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;fastai2.interpret&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#interp = Interpretation.from_learner(learn)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ClassificationInterpretation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;

&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_top_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea &quot;&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;input&lt;/th&gt;
      &lt;th&gt;target&lt;/th&gt;
      &lt;th&gt;predicted&lt;/th&gt;
      &lt;th&gt;probability&lt;/th&gt;
      &lt;th&gt;loss&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; ĠThis Ġmovie Ġis Ġhorrible - Ġin Ġa Ġ' so Ġbad Ġit 's Ġgood ' Ġkind Ġof Ġway .&amp;lt; br Ġ/ &amp;gt;&amp;lt; br Ġ/&amp;gt; The Ġstoryline Ġis Ġre h ashed Ġfrom Ġso Ġmany Ġother Ġfilms Ġof Ġthis Ġkind , Ġthat ĠI 'm Ġnot Ġgoing Ġto Ġeven Ġbother Ġdescribing Ġit . ĠIt 's Ġa Ġsword / s or cery Ġpicture , Ġhas Ġa Ġkid Ġhoping Ġto Ġrealize Ġhow Ġimportant Ġhe Ġis Ġin Ġthis Ġworld , Ġhas Ġa Ġ&quot; nom adic &quot; Ġadventurer , Ġan Ġevil Ġaide / s orce rer , Ġa Ġprincess , Ġa Ġhairy Ġcreature .... you Ġget Ġthe Ġpoint .&amp;lt; br Ġ/ &amp;gt;&amp;lt; br Ġ/&amp;gt; The Ġfirst Ġtime ĠI Ġcaught Ġthis Ġmovie Ġwas Ġduring Ġa Ġvery Ġharsh Ġwinter . ĠI Ġdon 't Ġknow Ġwhy ĠI Ġdecided Ġto Ġcontinue Ġwatching Ġit Ġfor Ġan Ġextra Ġfive Ġminutes Ġbefore Ġturning Ġthe Ġchannel , Ġbut Ġwhen ĠI Ġcaught Ġsite Ġof ĠGulf ax&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;negative&lt;/td&gt;
      &lt;td&gt;0.970687747001648&lt;/td&gt;
      &lt;td&gt;3.354750156402588&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; ĠIn Ġ17 th ĠCentury ĠJapan , Ġthere Ġlived Ġa Ġsamurai Ġwho Ġwould Ġset Ġthe Ġstandard Ġfor Ġthe Ġages . ĠHis Ġname Ġwas ĠMay eda . ĠHe Ġis Ġsent Ġon Ġan Ġepic Ġjourney Ġacross Ġthe Ġworld Ġto Ġacquire Ġ5 , 000 Ġmus cats Ġfrom Ġthe ĠKing Ġof ĠSpain . ĠWhilst Ġat Ġsea Ġa Ġviolent Ġstorm Ġswall ows Ġtheir Ġprecious Ġgold Ġintended Ġto Ġbuy Ġthe Ġweapons Ġand Ġalmost Ġtakes Ġtheir Ġlives . ĠMay eda Ġmust Ġbattle Ġall Ġodds Ġto Ġsurvive Ġand Ġthe Ġsecure Ġthe Ġfate Ġof Ġhis Ġbeloved ĠJapan . ĠShogun ĠMay eda Ġis Ġa Ġmulti Ġmillion Ġdollar Ġaction Ġadventure Ġepic Ġset Ġacross Ġthree Ġcontinents .&amp;lt; br Ġ/ &amp;gt;&amp;lt; br Ġ/&amp;gt; Star ring Ġcinema Ġlegends ĠSho ĠKos ugi Ġ( T ench u : ĠStealth ĠAssassins ), ĠChristopher ĠLee Ġ( Star ĠWars , ĠLord Ġof Ġthe ĠRings ĠTrilogy ), ĠJohn ĠRh ys ĠDavies Ġ( Lord Ġof Ġthe ĠRings ĠTrilogy , ĠIndiana ĠJones&lt;/td&gt;
      &lt;td&gt;negative&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;0.9588471055030823&lt;/td&gt;
      &lt;td&gt;3.033039093017578&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;&amp;lt;s&amp;gt; Ġ&quot; How ĠTo ĠLose ĠFriends Ġ&amp;amp; ĠAlien ate ĠPeople &quot; Ġis Ġnot Ġbased Ġon ĠTiger ĠWoods ' Ġinf idel ities . ĠIt Ġis Ġa Ġmediocre Ġromantic Ġcomedy Ġbased Ġon ĠToby ĠYoung 's Ġbook Ġon Ġhis Ġexperiences Ġworking Ġas Ġa Ġjournalist Ġcovering Ġcelebrities . ĠThe Ġfilm Ġstars ĠSimon ĠPe gg Ġas ĠSidney ĠYoung , Ġa Ġz any ĠBritish Ġjournalist Ġwho Ġtakes Ġa Ġjob Ġin Ġan Ġillustrious Ġcelebrity Ġmagazine Ġin ĠNew ĠYork . ĠYoung Ġis Ġrestless Ġin Ġgetting Ġcaught Ġup Ġall Ġtype Ġof Ġshenanigans Ġto Ġalien ate Ġall Ġaround Ġhim , Ġhence Ġmovie Ġtitle . ĠHe Ġis Ġupro arious , Ġdaring , Ġand Ġmor onic . ĠBut Ġnevertheless Ġfor Ġsome Ġvery Ġbizarre Ġreason , Ġhe Ġis Ġa Ġsomewhat Ġlik able Ġcharacter . ĠSidney Ġbe friends Ġa Ġfellow Ġjournalist , Ġthe Ġcomposed ĠAlison ĠOlsen , Ġplayed Ġquite Ġadm ir ably Ġby ĠKirst en ĠDun st . ĠHowever , ĠSidney Ġis Ġprimarily Ġlonging&lt;/td&gt;
      &lt;td&gt;positive&lt;/td&gt;
      &lt;td&gt;negative&lt;/td&gt;
      &lt;td&gt;0.942081868648529&lt;/td&gt;
      &lt;td&gt;2.7092723846435547&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;/div&gt;</content><author><name>Morgan McGuire</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.ntentional.com/images/fasthugs.png" /><media:content medium="image" url="https://www.ntentional.com/images/fasthugs.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">FixRes: ‘Fixing the train-test resolution discrepancy’</title><link href="https://www.ntentional.com/papers/training%20technique/classification/2020/04/15/fixres.html" rel="alternate" type="text/html" title="FixRes: 'Fixing the train-test resolution discrepancy'" /><published>2020-04-15T00:00:00-05:00</published><updated>2020-04-15T00:00:00-05:00</updated><id>https://www.ntentional.com/papers/training%20technique/classification/2020/04/15/fixres</id><content type="html" xml:base="https://www.ntentional.com/papers/training%20technique/classification/2020/04/15/fixres.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-15-fixres.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;TL;DR&quot;&gt;TL;DR&lt;a class=&quot;anchor-link&quot; href=&quot;#TL;DR&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The paper outlines two easy-to-implement tips to improve your image classification test results:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Do your inference on the test set at a &lt;strong&gt;higher resolution&lt;/strong&gt; than your train set&lt;/li&gt;
&lt;li&gt;Fine-tune the &lt;strong&gt;last layers&lt;/strong&gt; of your CNN classifier (i.e. the linear layer(s) after your pooling layer) at the higher test resolution&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;Overview&quot;&gt;Overview&lt;a class=&quot;anchor-link&quot; href=&quot;#Overview&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This article is a quick summary of &lt;a href=&quot;https://arxiv.org/abs/1906.06423&quot;&gt;'Fixing the train-test resolution discrepancy'&lt;/a&gt; from Hugo Touvron, Andrea Vedaldi, Matthijs Douze, Hervé Jégou from Facebook AI Research, presented at NeurIPS 2019, with additional data from the note &lt;a href=&quot;https://arxiv.org/pdf/2003.08237.pdf&quot;&gt;'Fixing the train-test resolution discrepancy: FixEfficientNet'&lt;/a&gt; from the same authors&lt;/p&gt;
&lt;h2 id=&quot;Results&quot;&gt;Results&lt;a class=&quot;anchor-link&quot; href=&quot;#Results&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Facebook AI Research (FAIR) used this technique to &lt;strong&gt;achieve a new SOTA result on Imagenet&lt;/strong&gt; (&lt;strong&gt;&lt;code&gt;88.5%&lt;/code&gt;&lt;/strong&gt; top-1 accuracy) using EfficientNet (using extra data)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200415_fixres_blog/fixeff.png&quot; alt=&quot;&quot; title=&quot;FixEfficientNet performance&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The authors also claim that it can &lt;strong&gt;enable faster training&lt;/strong&gt; by training at a lower resolution while still attaining similr/better results&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;
&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Our FixEfficientNet-L2 obtains a new state-of-the-art performance on ImageNet!&lt;br /&gt;You can find all our new results on the FixRes additional note (&lt;a href=&quot;https://t.co/mvY3EkGucR&quot;&gt;https://t.co/mvY3EkGucR&lt;/a&gt;) and also on &lt;a href=&quot;https://twitter.com/paperswithcode?ref_src=twsrc%5Etfw&quot;&gt;@paperswithcode&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/sotabench?ref_src=twsrc%5Etfw&quot;&gt;@sotabench&lt;/a&gt;&lt;br /&gt;(In case you missed the FixRes paper : &lt;a href=&quot;https://t.co/2NgQcrGDk5&quot;&gt;https://t.co/2NgQcrGDk5&lt;/a&gt;) &lt;a href=&quot;https://t.co/WiQtJQxdgT&quot;&gt;pic.twitter.com/WiQtJQxdgT&lt;/a&gt;&lt;/p&gt;&amp;mdash; Hugo Touvron (@HugoTouvron) &lt;a href=&quot;https://twitter.com/HugoTouvron/status/1242071277415870470?ref_src=twsrc%5Etfw&quot;&gt;March 23, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;But-Why?&quot;&gt;But Why?&lt;a class=&quot;anchor-link&quot; href=&quot;#But-Why?&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Using typical training transforms such as &lt;code&gt;RandomResizedCrop&lt;/code&gt; result in objects in training images appearing &lt;strong&gt;larger&lt;/strong&gt; than they do in the test set. Have a look at the example from the paper below.&lt;/p&gt;
&lt;p&gt;Our original image is resized to &lt;code&gt;224 x 224&lt;/code&gt; before it is shown to the model. &lt;code&gt;RandomResizedCrop&lt;/code&gt; is used to resize our training image (and add a little regularisation) while for the test image a simple center crop is taken. As a result of these different resizing methods, the size of the white horse in the top left training image is much larger than what would be shown to the model in the test set. It is this &lt;strong&gt;difference in object (e.g. horse) size&lt;/strong&gt; that the authors say that their FixRes technique addresses&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/copied_from_nb/my_icons/20200415_fixres_blog/horse_train_224.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In other words:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;...resizing the input images in pre-processing changes the distribution of objects sizes. Since different pre-processing protocols are used at training and testing time, the size distribution differs in the two cases.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;How?---Two-Tricks&quot;&gt;How? - Two Tricks&lt;a class=&quot;anchor-link&quot; href=&quot;#How?---Two-Tricks&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Test at a Higher Resolution&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Simply testing at a higher resolution should yield a performance improvement. Here, the authors show ImageNet top-1 test set accuracy trained at &lt;code&gt;224 x 224&lt;/code&gt;, you can see that the optimal test resolution was &lt;code&gt;288 x 288&lt;/code&gt;:&lt;img src=&quot;/images/copied_from_nb/my_icons/20200415_fixres_blog/k_test_acc.png&quot; alt=&quot;&quot; /&gt;
(This behaviour was previously been shown in 2016 in &lt;a href=&quot;https://arxiv.org/pdf/1603.05027.pdf&quot;&gt;&quot;Identity Mappings in Deep Residual Networks&quot;&lt;/a&gt;). Alternatively if you don't want to/cannot test at higher resolution, then training at a lower resolution is said to deliver the same accuracy, while &lt;strong&gt;enabling you to train faster&lt;/strong&gt; (as you will be able to use a larger batch size with your smaller image resolutions)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fine-tuning of later (classifier) layers of your CNN model&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;&lt;p&gt;For the convolutional part of the CNN, comprising linear convolution, subsampling, ReLU, and similar layers, changing the input crop size is approximately transparent because the receptive field is unaffected by the input size. However, for classification the network must be terminated by a pooling operator (usually average pooling) in order to produce a fixed-size vector. &lt;strong&gt;Changing the size of the input crop strongly affects the activation statistics of this layer&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When fine-tuning, the authors recommend using &lt;strong&gt;test-time augmentation, not the previous training augmentation&lt;/strong&gt; as it is simplest and performs well. Using training augmentations gave only slightly better results.&lt;/p&gt;
&lt;h2 id=&quot;Similarity-to-Fast.ai's-Progressive-Resizing&quot;&gt;Similarity to Fast.ai's Progressive Resizing&lt;a class=&quot;anchor-link&quot; href=&quot;#Similarity-to-Fast.ai's-Progressive-Resizing&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Interestingly this technique is a little similar to &lt;code&gt;Progressive Resizing&lt;/code&gt;, first espoused in the &lt;a href=&quot;www.fast.ai&quot;&gt;fast.ai&lt;/a&gt; deep learning course. The idea behind Progressive Resizing is that you first train at a lower resolution before increasing resolution and training again, albeit you're always training the entire network as opposed fine-tuning the classifier layers as described above. Nevertheless, it makes me wonder if both the FixRes and Progressive Resizing training techniques work via correcting for the same Train/Test object size mis-match?&lt;/p&gt;
&lt;p&gt;Any thoughts, comments, suggestions I'd love to hear from you &lt;a href=&quot;www.twitter.com/mcgenergy&quot;&gt;@mcgenergy&lt;/a&gt; on Twitter 😃&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Morgan McGuire</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://www.ntentional.com/images/20202_04_15_horse_train_224.png" /><media:content medium="image" url="https://www.ntentional.com/images/20202_04_15_horse_train_224.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>